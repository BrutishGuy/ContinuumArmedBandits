{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce305b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing the required libraries ##\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.gaussian_process import kernels\n",
    "#from continuum_gaussian_bandits import ContinuumArmedBandit, GPR\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.gaussian_process import kernels\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "import dill \n",
    "import argparse\n",
    "import datetime\n",
    "\n",
    "from google.api_core import retry\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import firestore\n",
    "from google.cloud import pubsub_v1\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18e91f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextualContinuumArmedBandit:\n",
    "    \"\"\"\n",
    "    This class implements a contextual version of the ContinuumArmedBandit, which extends it to work\n",
    "    in the contextual setting. We do this by augmenting the structure of the bandit to \n",
    "    incoroporate a contextual feature matrix. This identifies a unique context in which to train for \n",
    "    action/rewards. Thus, we train a ContinuumArmedBandit for each unique context encountered and use this\n",
    "    as our model structure. Model API follows closely that defined by scikit-learn and also that by ContinuumArmedBandit in that \n",
    "    it merely extends that class to work for the contextual setting by specifying a context ID whenever calling similarly named methods such as fit or predict.\n",
    "    \n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(self, contexts, oracle, bid_max_value=None, context_ids = None, convergence_rate=1.0, exploration_threshold=0.1, action_col_name='avg_cpc', kpi_name = 'avg_ctr'):\n",
    "        self.context_dict = {} # keep stored all the trained bandit models to be called for prediction later on.\n",
    "        \n",
    "        if type(contexts) != pd.core.frame.DataFrame:\n",
    "            print(\"WARNING: The contexts provided are not in the form of a Pandas DataFrame object. Attempting to convert, but no guarantees... \")\n",
    "            try:\n",
    "                contexts = pd.DataFrame(contexts)\n",
    "            except:\n",
    "                print(\"ERROR: Could not convert contexts into a Pandas DataFrame. Please transform it on the user end and pass as required...\")\n",
    "                raise\n",
    "                \n",
    "        if contexts.shape[0] != contexts.drop_duplicates().shape[0]:\n",
    "            print(\"ERROR: The contexts provided are not unique. Please provide only unique lists of context information, i.e. a context matrix, to instantiate a trained ContextualContinuumArmedBandit. Returning...\")\n",
    "            raise\n",
    "       \n",
    "        if not bid_max_value:\n",
    "            bid_max_value = 2.0\n",
    "        \n",
    "        # do not require a default list of context IDs. If none provided use a default index from 0 to N, the number of unique contexts\n",
    "        if not context_ids:\n",
    "            self.context_ids = np.arange(contexts.shape[0])\n",
    "        else:\n",
    "            self.context_ids = context_ids\n",
    "        self.contexts = contexts.copy(deep=True) # keep a dictionary or dataframe containing all the contexts we wish to keep track of\n",
    "        self.bid_max_value = bid_max_value # keep track of the max allowed bid value\n",
    "        self.action_col_name = action_col_name # keep track of the name of action column name, by default avg_cpc\n",
    "        self.kpi_name = kpi_name # keep track of the kpi name for optimization/i.e. to use as reward, default ctr\n",
    "        self.exploration_threshold = exploration_threshold\n",
    "        X = np.linspace(0, self.bid_max_value, 100)\n",
    "        # setting X to be a 2D matrix, one data point per dimension, such that the kernel treats each point separately\n",
    "\n",
    "        X_pred = np.atleast_2d(X).T\n",
    "        self.num_contexts = len(contexts)\n",
    "        # loop over the context IDs we\n",
    "        for context_id in self.context_ids:\n",
    "            print(\"INFO: Fitting continuum bandit for context: \" + str(context_id + 1))\n",
    "            df_context = pd.DataFrame(self.contexts.iloc[context_id, :]).transpose()\n",
    "            df_context = df_context.loc[df_context.index.repeat(len(X))].reset_index(drop=True)\n",
    "            df_context = pd.concat([df_context, pd.DataFrame({'avg_cpc': X})], axis = 1)\n",
    "            \n",
    "            #if not type(oracle) == google.cloud.aiplatform.models.Endpoint:\n",
    "            y_pred = oracle.predict(df_context)\n",
    "            #else:\n",
    "            #    y_preds = oracle.predict(instances=[df_context.to_json()])\n",
    "            # setting y to be a 2D matrix to match the dimensions of X when calculating the alpha parameter\n",
    "            y_pred = np.atleast_2d(y_pred).T\n",
    "            self.context_dict[self.context_ids[context_id]] = (ContinuumArmedBandit(X_pred, y_pred , convergence_rate=1.0), None, None)\n",
    "\n",
    "\n",
    "    def select_action(self, context_id):\n",
    "        \"\"\"\n",
    "        Select the next action to sample from. Can be thought of as similar to an acquisition function in Bayesian optimization\n",
    "        \n",
    "        Note\n",
    "        ----\n",
    "        context_id should preferably come from the same list of IDs as the contexts from the training data. It is very easy otherwise to predict for an incorrect context!\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        context_id : int\n",
    "            This is the ID of the context in our context matrix (represented via a Pandas DataFrame object) which we want to generate a prediction for\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        result : float\n",
    "            The result is the numeric action which will act as our next continuous action to take for this instance.\n",
    "            \n",
    "        \"\"\"\n",
    "        continuum_bandit = self.context_dict[context_id][0] # get the bandit trained algorithm for this context id\n",
    "        x = continuum_bandit.select_action() # query this bandits select_action() method to retrieve the next query point based on its acquisition function.\n",
    "        return x\n",
    "        \n",
    "    def get_x_best(self, X, context_id):\n",
    "        \"\"\"\n",
    "        Selects the next action to take based on the acquisition function defined for the continuum gaussian bandit        \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array(n_samples, ) \n",
    "            An array of points for which to calculate a merit score via the acquisition function of the bandit model\n",
    "            thus giving rise to candidate points to choose for the next query point x_best\n",
    "            \n",
    "        context_id : int type\n",
    "            The specific context id for which to retrieve the next best action to follow\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        x_best : float\n",
    "            The next best point to try sample at as the next action\n",
    "        \"\"\"\n",
    "        x_best = self.context_dict[context_id][0].get_x_best(X) # query the get_x_best function of the ContinuumArmedBandit associated with this context id\n",
    "        \n",
    "        return x_best\n",
    "\n",
    "\n",
    "    def update(self, df_contexts, actions, rewards, start_from_checkpoint=True):\n",
    "        \"\"\"\n",
    "        Updates the contextual bandit given newly observed rewards for the actions set by the model.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        df_contexts : array(n_contexts, n_features) or pd.DataFrame of shape (n_contexts, n_features)\n",
    "            Matrix of covariates for the available data.\n",
    "        actions : array(n_samples, ), float type\n",
    "            Arms or actions that were chosen for each observations.\n",
    "        rewards : array(n_samples, ), [0,1]\n",
    "            Rewards that were observed for the chosen actions. Must be binary rewards 0/1.\n",
    "        start_from_checkpoint : bool\n",
    "            If the policy was previously fit to data, \n",
    "            it will use previously trained models along with adding this new data to old data. In this case,\n",
    "            will only refit the models that have new data according to actions and rewards specified.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        self : obj\n",
    "            No return type\n",
    "        \"\"\"\n",
    "        # important checks to run, check of the object is of type dataframe\n",
    "        if type(df_contexts) != pd.core.frame.DataFrame:\n",
    "            print(\"WARNING: The contexts provided are not in the form of a Pandas DataFrame object. Attempting to convert, but no guarantees... \")\n",
    "            try:\n",
    "                df_contexts = pd.DataFrame(df_contexts)\n",
    "            except:\n",
    "                print(\"ERROR: Could not convert contexts into a Pandas DataFrame. Please transform it on the user end and pass as required...\")\n",
    "                raise\n",
    "                \n",
    "        # check if the data in the context matrix passed match what has been trained on historically\n",
    "        if not self.contexts.columns.isin(df_contexts.columns).all():\n",
    "            print(\"ERROR: Columns provided in df_contexts does not correspond to the column trained on for this model. Please provide a data frame matching the following column signature: \" + str(self.contexts.columns))\n",
    "            raise \n",
    "            \n",
    "        # check the reverse holds in case we have a different set in some slight way\n",
    "        if not df_contexts.columns.isin(self.contexts.columns).all():\n",
    "            print(\"ERROR: Columns provided in df_contexts does not correspond to the column trained on for this model. Please provide a data frame matching the following column signature: \" + str(self.contexts.columns))\n",
    "            raise \n",
    "            \n",
    "        # for each unique context, find the similar or corresponding context in our data and run this through the bandit model\n",
    "        # for this context, updating the actions and rewards following this.\n",
    "        for context_id in range(df_contexts.drop_duplicates().shape[0]):\n",
    "            try:\n",
    "                context = df_contexts.iloc[context_id, :]\n",
    "                \n",
    "                context_location = np.where((self.contexts == context).all(axis=1))[0][0] # getting the first possible index from the np.where results which are of the form np.array(np.array, dtype)\n",
    "                continuum_bandit = self.context_dict[context_location][0]\n",
    "                X = actions[context_id]\n",
    "                y = rewards[context_id]\n",
    "                continuum_bandit.update(X, y)\n",
    "                \n",
    "            except:\n",
    "                print(\"ERROR: Unsampled or unseen context, please update or re-fit the model with the context included.\")\n",
    "                raise\n",
    "        \n",
    "        \n",
    "    def fit(self, num_rounds):\n",
    "        \"\"\"\n",
    "        Continues to fit the model from the last trained point in terms of parameters. In essence, \n",
    "        \n",
    "        1) it samples a random context to train, \n",
    "        2) samples a next action point to query,\n",
    "        3) receives a reward from the oracle environment simulation model,\n",
    "        4) updates the bandit trained for this context       \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        num_rounds : int type \n",
    "            The number of iterations or samples which will be carried out for training of this model.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        \"\"\"\n",
    "        np.random.seed(42)\n",
    "        for round_num in num_rounds:\n",
    "            sample_context_id = np.random.randint(self.num_contexts)\n",
    "            sampled_context = self.contexts[sample_context_id]\n",
    "            continuum_bandit = self.context_dict[sample_context_id][0]\n",
    "            \n",
    "            epsilon = np.random.random() # pick a random number between 0 and 1\n",
    "            \n",
    "            # if the number is greater than the model exploration threshold\n",
    "            # pick a next query point based on select_action or using the model's acquisition function\n",
    "            # or just exploit the next best point in terms of known best strategy\n",
    "            if epsilon < self.exploration_threshold:\n",
    "                x = continuum_bandit.predict()\n",
    "            else:\n",
    "                x = continuum_bandit.select_action()\n",
    "            \n",
    "            y_pred = self.oracle.predict(sampled_context.append(x))\n",
    "            continuum_bandit.update(x, y_pred)\n",
    "            \n",
    "    \n",
    "    def predict(self, new_contexts):\n",
    "        \"\"\"\n",
    "        Using the currently trained-on parameters of the model, generate a series of predictions for the new contexts\n",
    "        provided to the model. This follows the following steps,\n",
    "        \n",
    "        1) it attemps to match currently known contexts to those provided,\n",
    "        2) with probability epsilon, retrieve a next action query point based on the model's acquisition function\n",
    "        3) otherwise do greedy-style exploitation of best known point\n",
    "        4) return the models best decision given the above.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        new_contexts : pd.DataFrame of shape (n_contexts, n_features)\n",
    "            The context feature matrix defining the unique contexts we would like to query for a prediction.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        df_results : pd.DataFrame of shape (n_contexts, n_features + 1)\n",
    "            This returns the above new_contexts dataframe object but we append a column to it with the next actions to be taken.\n",
    "            \n",
    "        \"\"\"\n",
    "        if type(new_contexts) != pd.core.frame.DataFrame:\n",
    "            print(\"WARNING: The contexts provided are not in the form of a Pandas DataFrame object. Attempting to convert, but no guarantees... \")\n",
    "            try:\n",
    "                new_contexts = pd.DataFrame(new_contexts)\n",
    "            except:\n",
    "                print(\"ERROR: Could not convert contexts into a Pandas DataFrame. Please transform it on the user end and pass as required...\")\n",
    "                raise\n",
    "                \n",
    "                \n",
    "        result_set = []\n",
    "        for context_id in range(new_contexts.drop_duplicates().shape[0]):\n",
    "            try:\n",
    "                context = self.contexts.iloc[context_id, :]\n",
    "                \n",
    "                context_location = np.where((self.contexts == context).all(axis=1))[0][0] # getting the first possible index from the np.where results which are of the form np.array(np.array, dtype)\n",
    "                continuum_bandit = self.context_dict[context_location][0] # getting the trained bandit model from the context_dict\n",
    "                \n",
    "                epsilon = 1.0 # random number, such that with prob. 0.1 we choose a random action to explore via select_action, and otherwise predict as usual\n",
    "            \n",
    "                if epsilon < self.exploration_threshold:\n",
    "                    x = continuum_bandit.select_action()\n",
    "                else:\n",
    "                    x = continuum_bandit.predict()\n",
    "            except:\n",
    "                print(\"ERROR: Unsampled or unseen context, please update or re-fit the model with the context included.\")\n",
    "                raise \n",
    "            result_set.append(x[0][0])\n",
    "            \n",
    "        df_results = pd.DataFrame(new_contexts.copy(deep=True)) # create deepcopy\n",
    "        df_results['avg_cpc'] = result_set\n",
    "        return df_results\n",
    "    \n",
    "    def partial_fit(self, contexts_new, X_new, y_new, reward_new):\n",
    "        \"\"\" TODO - for online bandit algorithm \"\"\"\n",
    "        for context in contexts_new:\n",
    "            try:\n",
    "                sampled_context = self.context_dict[context]\n",
    "            except:\n",
    "                print(\"ERROR: Unsampled or unseen context, please update or re-fit the model with the context included.\")\n",
    "                raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8adc6d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContinuumArmedBandit:\n",
    "    \"\"\"\n",
    "    This class implements ContinuumArmedBandit, which is a multi-armed bandit extended\n",
    "    to work in the continuous action space definition of the problem. The method of achieving this is \n",
    "    by keeping track of the distribution of rewards and expected rewards for each point in the action space.\n",
    "    In the usual MAB setting this boils down to keeping track of summary statistics for each action and using algorithms like\n",
    "    LinUCB, Exp3 etc. to sample from the space itself.\n",
    "    \n",
    "    In our case, we do something similar in that we use the methodology of LinUCB and use the upper confidence interval predicted\n",
    "    for the rewards around a given action in order to pick the next best action to sample, however, \n",
    "    we approximate the probabilities differently in this continuous setting: We use \n",
    "    Gaussian processes to approximate the distribution of rewards varying across our continuous action space!\n",
    "    \n",
    "    This allows us to use simple to use and easy to extend methods such as GaussianProcessRegressor from scikit-learn (see docs for more).\n",
    "    \n",
    "    We merely extend this class in the GPR implementation which accompanies this class, in order to implement this acquisition function approach in \n",
    "    order to sample our probability space for the next best action.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, convergence_rate=1.0):\n",
    "        \"\"\"\n",
    "        Intialize the class with the necessary X and y values, in this case representing the actions and rewards to train on, respectively.\n",
    "        The convergence rate determines by what factor to update the kernel and Gaussian parameters W, K, alpha and gamma\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array(n_samples, n_actions) or pd.DataFrame of shape (n_samples, n_actions)\n",
    "            The actions to train on. Usually n_actions is 1, meaning that shape (n_samples, ) results for both input types\n",
    "        y : array(n_samples, ) or pd.DataFrame or pd.Series of shape (n_samples, 1)\n",
    "            The rewards which result from the corresponding actions in X above.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "            \n",
    "        \"\"\"\n",
    "        self.X = X.copy()\n",
    "        self.y = y.copy() # set X and y as local parameters\n",
    "        self.gpr = GPR(self.X, self.y, convergence_rate=convergence_rate) # define our custom defined GaussianProcessRegressor model\n",
    "        self.N = self.X.shape[0]\n",
    "        self.convergence_rate = convergence_rate\n",
    "        self.alpha = self.calc_alpha(self.gpr.K, self.gpr.noise_var, self.y) # update the alpha values associated with reward or y-values\n",
    "        self.gamma = self.calc_gamma(self.gpr.K, self.gpr.noise_var, self.X) # update the gamma values associated with actions or data points or x-values\n",
    "\n",
    "    def select_action(self):\n",
    "        \"\"\"\n",
    "        Select the next action to sample from. Can be thought of as similar to an acquisition function in Bayesian optimization\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        x : float\n",
    "            The result is the numeric action which will act as our next continuous action to take for this instance.\n",
    "            \n",
    "        \"\"\"\n",
    "        x = self.get_x_best(self.X)\n",
    "        return x\n",
    "    \n",
    "    def update(self, X, y):\n",
    "        \"\"\"\n",
    "        Stacks the new X and y values onto the existing ones, updating the parameters of the model and hence refitting it totally on the new appended data.        \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array(n_samples, ) \n",
    "            An array of points which correspond to the action points to update the model with\n",
    "            \n",
    "        y : array(n_samples)\n",
    "            An array containing the associated reward values to model against X\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        \"\"\"\n",
    "        self.X = np.vstack((self.X, X)) # append copies of this dataset in the locally stored class values\n",
    "        self.y = np.vstack((self.y, y)) \n",
    "        self.gpr = GPR(self.X, self.y, convergence_rate=self.convergence_rate)\n",
    "        self.N = self.X.shape[0] # update dataset size convenience parameter\n",
    "\n",
    "\n",
    "        self.alpha = self.calc_alpha(self.gpr.K, self.gpr.noise_var, self.y) # update alpha for this new dataset and post-retraining of the GPR model\n",
    "        self.gamma = self.calc_gamma(self.gpr.K, self.gpr.noise_var, self.X) # update gamma for this new dataset and post-retraining of the GPR model-retraining of the GPR model\n",
    "\n",
    "    def get_x_best(self, X):\n",
    "        \"\"\"\n",
    "        Selects the next action to take based on the acquisition function defined for the continuum gaussian bandit        \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array(n_samples, ) \n",
    "            An array of points for which to calculate a merit score via the acquisition function of the bandit model\n",
    "            thus giving rise to candidate points to choose for the next query point x_best\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        x_best : float\n",
    "            The next best point to try sample at as the next action\n",
    "        \"\"\"\n",
    "        \n",
    "        merit_best = 0\n",
    "        x_best = None\n",
    "        for j in range(self.N):\n",
    "            x = X[j]\n",
    "            s = self.get_s(x, X)\n",
    "            x = x + s\n",
    "            x_merit = self.get_merit(x, X)\n",
    "            if x_merit > merit_best:\n",
    "                x_best = x\n",
    "                merit_best = x_merit\n",
    "        return x_best\n",
    "\n",
    "    def get_s(self, x, X):\n",
    "        \"\"\"\n",
    "        Returns the mean prediction for the value x relative to the action space X, with confidence envelope s. \n",
    "        Works in the derivative space to approximate gradients of the model fit       \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : float type\n",
    "            the action query point to evaluate the mean and standard deviation derivatives for following from the kernel function\n",
    "        X : array(n_samples, ) \n",
    "            An array of points which correspond to the action points to update the model with\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        s : float\n",
    "            The derivative mean prediction for point x relative to X with derivative envelope \n",
    "        \"\"\"\n",
    "        der_mean = self.get_derivative_mean(x, X)\n",
    "        der_std = self.get_derivative_std(x, X)\n",
    "        s = der_mean + der_std\n",
    "        return s\n",
    "    \n",
    "    def get_derivative_std(self, x, X):\n",
    "        \"\"\"\n",
    "        Returns the derivative standard deviation prediction for the point x relative to action space data X w.r.t. the kernel       \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : float type\n",
    "            the action query point to evaluate the mean and standard deviation derivatives for following from the kernel function\n",
    "        X : array(n_samples, ) \n",
    "            An array of points which correspond to the action points to update the model with\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        s : float\n",
    "            The derivative standard deviation envelope for point x relative to X w.r.t. the kernel\n",
    "        \"\"\"\n",
    "        der_std = 0\n",
    "        W = self.gpr.W\n",
    "        k_prime = self.gpr.k\n",
    "        std = self.get_std(x, X)\n",
    "        for i in range(self.N):\n",
    "            for j in range(self.N):\n",
    "                der_std += (2.0 / std) * self.gamma[i,j] * W.dot((X[i] + X[j]) / 2.0 - x) * k_prime(x, (X[i] + X[j]) / 2.0) \n",
    "        return der_std\n",
    "\n",
    "\n",
    "    def get_derivative_mean(self, x, X):\n",
    "        \"\"\"\n",
    "        Retrieves the model kernel for the dataset X provided. TODO: update this method to simply use self.X. \n",
    "        At the moment uses a user provided X, which in this case is self.X passed internally among the class methods.\n",
    "        \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array(n_samples, ) \n",
    "            An array of points which correspond to the action points to update the model with\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        kernel : sklearn.gaussian_process.kernels types\n",
    "            A kernel class which consists of the kernel matrix with normalized length scales along each dimension of X, determined by X.shape[1] of course. \n",
    "            it is a combination between a radial basis function kernel and some white noise\n",
    "        \"\"\"\n",
    "        der_mean = 0\n",
    "        W = self.gpr.W\n",
    "        k = self.gpr.k\n",
    "        for i in range(self.N):\n",
    "            der_mean += W.dot(X[i] - x) * k(x, X[i]) * self.alpha[i]\n",
    "        return der_mean\n",
    "\n",
    "\n",
    "    def get_merit(self, x, X):\n",
    "        \"\"\"\n",
    "        Retrieves the model kernel for the dataset X provided. TODO: update this method to simply use self.X. \n",
    "        At the moment uses a user provided X, which in this case is self.X passed internally among the class methods.\n",
    "        \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array(n_samples, ) \n",
    "            An array of points which correspond to the action points to update the model with\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        kernel : sklearn.gaussian_process.kernels types\n",
    "            A kernel class which consists of the kernel matrix with normalized length scales along each dimension of X, determined by X.shape[1] of course. \n",
    "            it is a combination between a radial basis function kernel and some white noise\n",
    "        \"\"\"\n",
    "        mean = self.get_mean(x, X)\n",
    "        var = self.get_std(x, X)\n",
    "        merit = mean + var\n",
    "        return merit\n",
    "    \n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        Retrieves the model kernel for the dataset X provided. TODO: update this method to simply use self.X. \n",
    "        At the moment uses a user provided X, which in this case is self.X passed internally among the class methods.\n",
    "        \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array(n_samples, ) \n",
    "            An array of points which correspond to the action points to update the model with\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        kernel : sklearn.gaussian_process.kernels types\n",
    "            A kernel class which consists of the kernel matrix with normalized length scales along each dimension of X, determined by X.shape[1] of course. \n",
    "            it is a combination between a radial basis function kernel and some white noise\n",
    "        \"\"\"\n",
    "        test_x = np.linspace(0.01, np.max(self.X))\n",
    "        \n",
    "        val_pred, val_var = self.predict_reward(np.atleast_2d(test_x).T)\n",
    "        \n",
    "        \n",
    "        action_idx = np.where(val_pred + val_var == np.max(val_pred + val_var))\n",
    "        action = self.X[action_idx]\n",
    "        \n",
    "        return action\n",
    "        \n",
    "    \n",
    "    def predict_reward(self, x_arr):\n",
    "        \"\"\"\n",
    "        Retrieves the model kernel for the dataset X provided. TODO: update this method to simply use self.X. \n",
    "        At the moment uses a user provided X, which in this case is self.X passed internally among the class methods.\n",
    "        \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array(n_samples, ) \n",
    "            An array of points which correspond to the action points to update the model with\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        kernel : sklearn.gaussian_process.kernels types\n",
    "            A kernel class which consists of the kernel matrix with normalized length scales along each dimension of X, determined by X.shape[1] of course. \n",
    "            it is a combination between a radial basis function kernel and some white noise\n",
    "        \"\"\"\n",
    "        val_pred = []\n",
    "        val_var = []\n",
    "        for x in x_arr:\n",
    "            mean = self.get_mean(x, self.X)\n",
    "            var = self.get_std(x, self.X)\n",
    "            val_pred.append(mean)\n",
    "            val_var.append(var)\n",
    "        return val_pred, val_var\n",
    "\n",
    "    def get_mean(self, x, X):\n",
    "        \"\"\"\n",
    "        Retrieves the model kernel for the dataset X provided. TODO: update this method to simply use self.X. \n",
    "        At the moment uses a user provided X, which in this case is self.X passed internally among the class methods.\n",
    "        \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array(n_samples, ) \n",
    "            An array of points which correspond to the action points to update the model with\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        kernel : sklearn.gaussian_process.kernels types\n",
    "            A kernel class which consists of the kernel matrix with normalized length scales along each dimension of X, determined by X.shape[1] of course. \n",
    "            it is a combination between a radial basis function kernel and some white noise\n",
    "        \"\"\"\n",
    "        mean = 0\n",
    "        k = self.gpr.k\n",
    "        for j in range(self.N):\n",
    "            mean += k(x,X[j]) * self.alpha[j]\n",
    "        return mean\n",
    "\n",
    "    def get_std(self, x, X):\n",
    "        \"\"\"\n",
    "        Retrieves the model kernel for the dataset X provided. TODO: update this method to simply use self.X. \n",
    "        At the moment uses a user provided X, which in this case is self.X passed internally among the class methods.\n",
    "        \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array(n_samples, ) \n",
    "            An array of points which correspond to the action points to update the model with\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        kernel : sklearn.gaussian_process.kernels types\n",
    "            A kernel class which consists of the kernel matrix with normalized length scales along each dimension of X, determined by X.shape[1] of course. \n",
    "            it is a combination between a radial basis function kernel and some white noise\n",
    "        \"\"\"\n",
    "        \n",
    "        k = self.gpr.k\n",
    "        k_prime = self.gpr.k_prime\n",
    "        kxx = k(x,x)\n",
    "        a = 0\n",
    "        for i in range(self.N):\n",
    "            for j in range(self.N):\n",
    "                a += k_prime(x, 0.5 * (X[i] + X[j])) * self.gamma[i,j]\n",
    "        var = np.sqrt(kxx - a)\n",
    "        return var\n",
    "        \n",
    "    def calc_alpha(self, K, noise_var, y):\n",
    "        \"\"\"\n",
    "        Retrieves the model kernel for the dataset X provided. TODO: update this method to simply use self.X. \n",
    "        At the moment uses a user provided X, which in this case is self.X passed internally among the class methods.\n",
    "        \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array(n_samples, ) \n",
    "            An array of points which correspond to the action points to update the model with\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        kernel : sklearn.gaussian_process.kernels types\n",
    "            A kernel class which consists of the kernel matrix with normalized length scales along each dimension of X, determined by X.shape[1] of course. \n",
    "            it is a combination between a radial basis function kernel and some white noise\n",
    "        \"\"\"\n",
    "        alpha = np.linalg.inv((K + noise_var * np.eye(self.N))).dot(y)\n",
    "        return alpha\n",
    "    \n",
    "    def calc_gamma(self, K, noise_var, X):\n",
    "        \"\"\"\n",
    "        Retrieves the kernel matrix for the dataset X provided. TODO: update this method to simply use self.X. \n",
    "        At the moment uses a user provided X, which in this case is self.X passed internally among the class methods.\n",
    "        \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array(n_samples, ) \n",
    "            An array of points which correspond to the action points to update the model with\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        kernel : array(n_actions, n_actions) type, n_action = X.shape[0]\n",
    "            A kernel matrix with shape the first dimension of X, determined by X.shape[0] of course. \n",
    "            it is a matrix which applies the kernel function of choice to each point in the data\n",
    "        \"\"\"\n",
    "        beta = self.get_Beta(X)\n",
    "        gamma = np.multiply(np.linalg.inv((K + noise_var * np.eye(self.N))), beta)\n",
    "        return gamma\n",
    "    \n",
    "    def get_Beta(self, X):\n",
    "        \"\"\"\n",
    "        Retrieves the Beta matrix for the dataset X provided. TODO: update this method to simply use self.X. \n",
    "        At the moment uses a user provided X, which in this case is self.X passed internally among the class methods.\n",
    "        \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array(n_samples, ) \n",
    "            An array of points which correspond to the action points to update the model with\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Beta : array(n_actions, n_actions) type, n_action = X.shape[0]\n",
    "            A beta matrix with shape the first dimension of X, determined by X.shape[0] of course. \n",
    "            it is a matrix which applies the beta function of choice to each point in the data\n",
    "        \"\"\"\n",
    "        N = X.shape[0]\n",
    "        Beta = np.zeros((N,N))\n",
    "        for i in range(N):\n",
    "            for j in range(N):\n",
    "                Beta[i,j] = self.beta(X[i], X[j])\n",
    "        return Beta\n",
    "    \n",
    "    def beta(self, x1, x2):\n",
    "        \"\"\"\n",
    "        Retrieves the beta coefficient between x1 and x2, which is an unscaled kernel function between them used in calculating self.beta\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x1 : float \n",
    "            A specific point to calculate beta_x1x2  \n",
    "        x2 : float \n",
    "            A specific point to calculate beta_x1x2\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        beta_x1x2 : float\n",
    "            The average  beta for x1, x2\n",
    "        \"\"\"\n",
    "        W = self.gpr.W\n",
    "        beta_x1x2 = np.exp(-0.25 * (x1 - x2).T.dot(W).dot(x1 - x2))\n",
    "        return beta_x1x2\n",
    "\n",
    "    def get_q_mean(self, x, X):\n",
    "        \"\"\"\n",
    "        Calculates the mean q value or q parameter of x given data X, using the second kernel function derivative.\n",
    "        \n",
    "        This can be interpreted as the average change in the slope relative to other data points\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : float\n",
    "            A specific point to calculate q at relative to X\n",
    "        X : array(n_samples, ) \n",
    "            An array of points which correspond to the action points to update the model with\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        q_mean : float\n",
    "            The average value of q for x given X\n",
    "        \"\"\"\n",
    "        q_mean = 0\n",
    "        kpp = self.gpr.k_prime_prime\n",
    "        for i in range(self.N):\n",
    "            q_mean += np.absolute(kpp(x, X[i])) * self.alpha[i]\n",
    "        return q_mean\n",
    "\n",
    "class GPR(GaussianProcessRegressor):\n",
    "    def __init__(self, X, y, convergence_rate=1.0):\n",
    "        \"\"\"\n",
    "        Intialize the class with the necessary X and y values, in this case representing the actions and rewards to train on, respectively.\n",
    "        The convergence rate determines by what factor to update the kernel and Gaussian parameters W, K, alpha and gamma\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array(n_samples, n_actions) or pd.DataFrame of shape (n_samples, n_actions)\n",
    "            The actions to train on. Usually n_actions is 1, meaning that shape (n_samples, ) results for both input types\n",
    "        y : array(n_samples, ) or pd.DataFrame or pd.Series of shape (n_samples, 1)\n",
    "            The rewards which result from the corresponding actions in X above.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        self.X = X # set the data set and initialize some class variables\n",
    "        self.y = y\n",
    "        self.W = None\n",
    "        self.K = None\n",
    "        self.noise_var = None\n",
    "        self.converge_rate_sq = np.power(convergence_rate, 2) # set the square of the convergence for the super model\n",
    "        GaussianProcessRegressor.__init__(self, kernel=self.get_kernel(self.X)) # get the kernel corresponding to this dataset\n",
    "        self.fit(self.X, self.y) # fit the model using the super class fit method\n",
    "        self.update_W() # update the W matrix with length scale parameters\n",
    "        self.update_K(self.X) # update the kernel matrix using the kernel and the dataset\n",
    "        self.update_noise_var() # update the noise variable using the super class noise variable definition\n",
    "\t\n",
    "    def update(self, X, y):\n",
    "        \"\"\"\n",
    "        Stacks the new X and y values onto the existing ones, updating the parameters of the model and hence refitting it totally on the new appended data.        \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array(n_samples, ) \n",
    "            An array of points which correspond to the action points to update the model with\n",
    "            \n",
    "        y : array(n_samples)\n",
    "            An array containing the associated reward values to model against X\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        self.X = np.vstack((self.X, X.copy()))\n",
    "        self.y = np.append(self.y, y.copy())\n",
    "        self.fit(self.X, self.y)\n",
    "        self.update_W()\n",
    "        self.update_K(self.X)\n",
    "        self.update_noise_var()\n",
    "    \n",
    "    def get_kernel(self, X):\n",
    "        \"\"\"\n",
    "        Retrieves the model kernel for the dataset X provided. TODO: update this method to simply use self.X. \n",
    "        At the moment uses a user provided X, which in this case is self.X passed internally among the class methods.\n",
    "        \n",
    "        Notes\n",
    "        -----\n",
    "        \n",
    "        TODO: Adjust the kernel to be problem specific. This is very hard to do generally, as it requires domain specific knowledge in ranges of values\n",
    "        your features will take. See here for more explanation. \n",
    "        \n",
    "        SEE HERE: https://github.com/scikit-learn/scikit-learn/issues/7563\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array(n_samples, ) \n",
    "            An array of points which correspond to the action points to update the model with\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        kernel : sklearn.gaussian_process.kernels types\n",
    "            A kernel class which consists of the kernel matrix with normalized length scales along each dimension of X, determined by X.shape[1] of course. \n",
    "            it is a combination between a radial basis function kernel and some white noise\n",
    "        \"\"\"\n",
    "        length_scale = np.random.normal(loc=1.0,scale=.1,size=X.shape[1])\n",
    "        rbf = kernels.RBF(length_scale=length_scale)\n",
    "        # we set these particular levels of noise to ensure better convergence of the GPR (tested in practice to work better)\n",
    "        wk = kernels.WhiteKernel(noise_level=1e-5, noise_level_bounds=(1e-10, 1e-4))\n",
    "        kernel = rbf + wk\n",
    "        return kernel\n",
    "\n",
    "    def update_K(self, X):\n",
    "        \"\"\"\n",
    "        Retrieves the kernel matrix for the dataset X provided. TODO: update this method to simply use self.X. \n",
    "        At the moment uses a user provided X, which in this case is self.X passed internally among the class methods.\n",
    "        \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array(n_samples, ) \n",
    "            An array of points which correspond to the action points to update the model with\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        kernel : array(n_actions, n_actions) type, n_action = X.shape[0]\n",
    "            A kernel matrix with shape the first dimension of X, determined by X.shape[0] of course. \n",
    "            it is a matrix which applies the kernel function of choice to each point in the data\n",
    "        \"\"\"\n",
    "        N = X.shape[0]\n",
    "        K = np.zeros((N,N)) # generate empty N x N matrix of zeroes to instantiate\n",
    "        for i in range(N):\n",
    "            for j in range(N):\n",
    "                K[i,j] = self.k(X[i], X[j]) # apply kernel function of choice defined below to each pair of data points\n",
    "        self.K = K # set the kernel in the class variables\n",
    "\n",
    "    def update_W(self):\n",
    "        \"\"\"\n",
    "        Retrieves the kernel matrix for the dataset X provided. TODO: update this method to simply use self.X. \n",
    "        At the moment uses a user provided X, which in this case is self.X passed internally among the class methods.\n",
    "        \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array(n_samples, ) \n",
    "            An array of points which correspond to the action points to update the model with\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        kernel : sklearn.gaussian_process.kernels types\n",
    "            A kernel class which consists of the kernel matrix with normalized length scales along each dimension of X, determined by X.shape[1] of course. \n",
    "            it is a combination between a radial basis function kernel and some white noise\n",
    "        \"\"\"\n",
    "        length_scales = self.kernel_.get_params()['k1__length_scale']\n",
    "        if len(self.X.shape) == 1 or self.X.shape[1] == 1:\n",
    "            length_scales = np.array([length_scales]) # length scales is a singular number, because X is a one dimensional dataset, hence we make it into an array\n",
    "            \n",
    "        w = 1.0 / np.power(length_scales, 2)\n",
    "        W = np.diag(w)\n",
    "        self.W = W\n",
    "\n",
    "    def update_noise_var(self):\n",
    "        \"\"\"\n",
    "        Updates the noise variable in the GaussianProcessRegressor model and internally based on updated values\n",
    "        of self.X and self.y\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        \"\"\"\n",
    "        noise_var = self.kernel_.get_params()['k2__noise_level']\n",
    "        self.noise_var = noise_var\n",
    "\n",
    "\n",
    "    def k(self, x1, x2):\n",
    "        \"\"\"\n",
    "        Kernel function defined as variant of matern kernel. Takes in two numeric vectors, x1 and x2 from\n",
    "        the data self.X and applies the kernel to them. Returns kernel value to be used in \n",
    "        constructing a kernel matrix\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x1 : float or array(1, n_dim) if multi-dimensional.\n",
    "            The first data point to be applied against the kernel with x2\n",
    "        x2 : float or array(1, n_dim) if multi-dimensional.\n",
    "            The second data point to be applied against the kernel with x1\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        k_x2x2 : float type\n",
    "            The return value which is the result of the kernel function applied to x1 and x2\n",
    "            \n",
    "        \"\"\"\n",
    "        k_x1x2 = self.converge_rate_sq * np.exp(-0.5 * (x1 - x2).T.dot(self.W).dot(x1 - x2))\n",
    "        return k_x1x2\n",
    "\n",
    "    def k_prime(self, x1, x2):\n",
    "        \"\"\"\n",
    "        Kernel first derivative of the usual kernel function defined in self.k\n",
    "        This is a helper function for calculating gradients, increases, decreases etc.\n",
    "        When arriving at query points via the acquisition functions\n",
    "\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x1 : float or array(1, n_dim) if multi-dimensional.\n",
    "            The first data point to be applied against the kernel with x2\n",
    "        x2 : float or array(1, n_dim) if multi-dimensional.\n",
    "            The second data point to be applied against the kernel with x1\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        k_x2x2 : float type\n",
    "            The return value which is the result of the kernel function applied to x1 and x2\n",
    "            \n",
    "        \"\"\"\n",
    "        k_prime_x1x2 = self.converge_rate_sq * np.exp(-1.0 * (x1 - x2).T.dot(self.W).dot(x1 - x2))\n",
    "        return k_prime_x1x2\n",
    "             \n",
    "    def k_prime_prime(self, x1, x2):\n",
    "        \"\"\"\n",
    "        Kernel second derivative of the usual kernel function defined in self.k\n",
    "        This is a helper function for calculating gradients, increases, decreases etc.\n",
    "        When arriving at query points via the acquisition functions\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x1 : float or array(1, n_dim) if multi-dimensional.\n",
    "            The first data point to be applied against the kernel with x2\n",
    "        x2 : float or array(1, n_dim) if multi-dimensional.\n",
    "            The second data point to be applied against the kernel with x1\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        k_x2x2 : float type\n",
    "            The return value which is the result of the kernel function applied to x1 and x2\n",
    "            \n",
    "        \"\"\"\n",
    "        k_prime_prime_x1x2 = self.converge_rate_sq * np.exp(-1.0/6.0 * (x1 - x2).T.dot(self.W).dot(x1 - x2))\n",
    "        return k_prime_prime_x1x2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9ffd6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = 'aa-cmab-product'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57d3fe42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|| 2/2 [00:00<00:00, 945.73query/s]                         \n",
      "Downloading: 100%|| 32757/32757 [00:01<00:00, 29665.69rows/s]\n"
     ]
    }
   ],
   "source": [
    "%%bigquery df_ad_group_summary --project $project_id\n",
    "select * from `aa-cmab-product.RawData.ProductionProcessedData`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "018d9bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bigquery_table(df):\n",
    "    \"\"\"\n",
    "    Example usage of models, oracle models etc.training them using a locally downloaded CSV file in the form of the JOT Google Ads\n",
    "    file data schema (see ./docs/data_docs/). We preprocess the raw docs in the form that it is done to put it into the BigQuery ProductionProcessedData table\n",
    "    \n",
    "    Trains a catboost oracle model and then trains a bandit using this model.\n",
    "\n",
    "    Additional fitting can be done via the fit_rounds, set to 0, or add more.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset_name : str\n",
    "        Example file of the form JOT Google Ads export\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    #dataset_name='C:\\\\Users\\\\PrasunGhosh\\\\Desktop\\\\OPERATIONAL_TESTING_DataSet-Final-Amplify_202108_20210823_QID10507419_20210824_125858_0.txt'\n",
    "    #df = pd.read_csv('C:\\\\Users\\\\PrasunGhosh\\\\Desktop\\\\OPERATIONAL_TESTING_DataSet-Final-Amplify_202108_20210823_QID10507419_20210824_125858_0.txt', delimiter='\\t')\n",
    "    #df.columns = ['client_id',\n",
    "    #              'campaign_id',\n",
    "    #              'group_id',\n",
    "    #              'account_descriptive_name',\n",
    "    #              'ad_network_type',\n",
    "    #              'avg_position',\n",
    "    #              'campaign_name',\n",
    "    #              'city_criteria_id',\n",
    "    #              'clicks',\n",
    "    #              'cost',\n",
    "    #              'impressions',\n",
    "    #              'country_criteria_id',\n",
    "    #              'date',\n",
    "    #              'device',\n",
    "    #              'external_customer_id',\n",
    "    #              'metro_criteria_id',\n",
    "    #              'region_criteria_id']\n",
    "\n",
    "    #df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n",
    "    #df['week_day'] = df['date'].dt.day_name()\n",
    "    #df['weekday_num'] = df['date'].dt.week\n",
    "    #\n",
    "    #id_fields = ['client_id', 'campaign_id', 'group_id', 'city_criteria_id',\n",
    "    #       'country_criteria_id', 'external_customer_id', 'metro_criteria_id',\n",
    "    #       'region_criteria_id']\n",
    "    #\n",
    "    #df[id_fields] = df[id_fields].astype(object)\n",
    "    \n",
    "    group_by_fields = ['client_id',\n",
    "    'external_customer_id',\n",
    "    'group_id', \n",
    "    'account_descriptive_name', \n",
    "    'ad_network_type',\n",
    "    'campaign_id', \n",
    "    'campaign_name',  \n",
    "    'week_day',\n",
    "    'weekday_num']\n",
    "    \n",
    "    \n",
    "    #df_grouped = df.groupby(group_by_fields).agg({'clicks': ['mean', 'sum'], 'impressions': 'sum', 'cost': ['mean', 'sum']}).reset_index()\n",
    "    #df_grouped.columns = [\"_\".join(a) for a in df_grouped.columns.to_flat_index()]\n",
    "    #df_grouped.columns=df_grouped.columns.str.strip('_')\n",
    "    #df_grouped['cost_sum'] = df_grouped['cost_sum']/1000000\n",
    "    #df_grouped['cost_sum'] = df_grouped['cost_sum']/1000000\n",
    "    #df_grouped['avg_ctr'] = df_grouped['clicks_sum']/df_grouped['impressions_sum']\n",
    "    #df_grouped['avg_cpc'] = df_grouped['cost_sum']/df_grouped['clicks_sum']\n",
    "    #df_grouped['total_cost'] = df_grouped['cost_sum']\n",
    "    #df_grouped['total_clicks'] = df_grouped['clicks_sum']\n",
    "    #df_grouped['total_impressions'] = df_grouped['impressions_sum']\n",
    "    #df_grouped['avg_clicks'] = df_grouped['clicks_mean']\n",
    "    #df_grouped['avg_cost'] = df_grouped['cost_mean']\n",
    "    \n",
    "    df_grouped=df\n",
    "    \n",
    "    df_grouped = df_grouped.drop(['weekday_num','clicks_sum', 'impressions_sum', 'cost_sum', 'cost_mean', 'clicks_mean'], axis=1, errors='ignore')\n",
    "    df_grouped = df_grouped.fillna(0)\n",
    "    df_grouped = df_grouped[df_grouped.avg_cpc > 0]\n",
    "    \n",
    "    df_train = df_grouped.drop(['avg_cpc', 'avg_ctr'], axis=1)\n",
    "    \n",
    "    group_by_fields.remove('weekday_num')\n",
    "    print(df_grouped.columns)\n",
    "    \n",
    "    group_by_fields = ['client_id',\n",
    "    'external_customer_id',\n",
    "    'group_id', \n",
    "    'account_descriptive_name', \n",
    "    'ad_network_type',\n",
    "    'campaign_id', \n",
    "    'campaign_name',  \n",
    "    'week_day']\n",
    "\n",
    "    train_data = df_grouped[group_by_fields + ['avg_cpc']]\n",
    "    \n",
    "    train_labels = df_grouped['avg_ctr']\n",
    "    \n",
    "    df_train=df_train[group_by_fields]\n",
    "\n",
    "    \n",
    "    cat_features = [i for i in range(len(group_by_fields))]\n",
    "    model = CatBoostRegressor(iterations=1000)\n",
    "    model.fit(train_data,\n",
    "              train_labels,\n",
    "              cat_features,\n",
    "              verbose=True)\n",
    "    \n",
    "    \n",
    "    train_preds = model.predict(train_data)\n",
    "    \n",
    "    \n",
    "    print('RMSE error of catboost oracle: ' + str(np.sqrt(mean_squared_error(train_labels, train_preds))))\n",
    "    print('Median of target variable: ' + str(np.median(train_labels)))\n",
    "    print('Mean of target variable: ' + str(np.mean(train_labels)))\n",
    "    # train the bandit example\n",
    "    df_train=df_train.drop_duplicates().reset_index()\n",
    "    bandit = ContextualContinuumArmedBandit(df_train, model, bid_max_value=1.0)\n",
    "    \n",
    "    dill.dump(bandit, open(\"training data/ContextualContinuumArmedBanditCloud_JOT.dill\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05d618ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['client_id', 'external_customer_id', 'group_id',\n",
      "       'account_descriptive_name', 'ad_network_type', 'campaign_id',\n",
      "       'campaign_name', 'week_day', 'total_clicks', 'total_cost', 'avg_clicks',\n",
      "       'avg_cost', 'total_impressions', 'avg_cpc', 'avg_ctr'],\n",
      "      dtype='object')\n",
      "Learning rate set to 0.064091\n",
      "0:\tlearn: 0.0641194\ttotal: 10.1ms\tremaining: 10.1s\n",
      "1:\tlearn: 0.0631663\ttotal: 13.8ms\tremaining: 6.88s\n",
      "2:\tlearn: 0.0622386\ttotal: 19.2ms\tremaining: 6.39s\n",
      "3:\tlearn: 0.0614054\ttotal: 28.1ms\tremaining: 6.99s\n",
      "4:\tlearn: 0.0606090\ttotal: 35ms\tremaining: 6.97s\n",
      "5:\tlearn: 0.0599306\ttotal: 40.5ms\tremaining: 6.71s\n",
      "6:\tlearn: 0.0592829\ttotal: 46.7ms\tremaining: 6.63s\n",
      "7:\tlearn: 0.0587108\ttotal: 51.9ms\tremaining: 6.43s\n",
      "8:\tlearn: 0.0581476\ttotal: 57.8ms\tremaining: 6.37s\n",
      "9:\tlearn: 0.0576551\ttotal: 63ms\tremaining: 6.24s\n",
      "10:\tlearn: 0.0572302\ttotal: 68.3ms\tremaining: 6.14s\n",
      "11:\tlearn: 0.0567399\ttotal: 75ms\tremaining: 6.17s\n",
      "12:\tlearn: 0.0563244\ttotal: 81.1ms\tremaining: 6.16s\n",
      "13:\tlearn: 0.0559283\ttotal: 87.1ms\tremaining: 6.14s\n",
      "14:\tlearn: 0.0555018\ttotal: 95.6ms\tremaining: 6.28s\n",
      "15:\tlearn: 0.0551523\ttotal: 102ms\tremaining: 6.28s\n",
      "16:\tlearn: 0.0548106\ttotal: 108ms\tremaining: 6.22s\n",
      "17:\tlearn: 0.0545170\ttotal: 113ms\tremaining: 6.16s\n",
      "18:\tlearn: 0.0542045\ttotal: 120ms\tremaining: 6.2s\n",
      "19:\tlearn: 0.0539276\ttotal: 127ms\tremaining: 6.21s\n",
      "20:\tlearn: 0.0536893\ttotal: 132ms\tremaining: 6.16s\n",
      "21:\tlearn: 0.0534497\ttotal: 138ms\tremaining: 6.13s\n",
      "22:\tlearn: 0.0532460\ttotal: 143ms\tremaining: 6.08s\n",
      "23:\tlearn: 0.0530306\ttotal: 150ms\tremaining: 6.08s\n",
      "24:\tlearn: 0.0528847\ttotal: 156ms\tremaining: 6.08s\n",
      "25:\tlearn: 0.0527708\ttotal: 161ms\tremaining: 6.04s\n",
      "26:\tlearn: 0.0526584\ttotal: 169ms\tremaining: 6.1s\n",
      "27:\tlearn: 0.0525468\ttotal: 177ms\tremaining: 6.15s\n",
      "28:\tlearn: 0.0524441\ttotal: 184ms\tremaining: 6.17s\n",
      "29:\tlearn: 0.0523415\ttotal: 190ms\tremaining: 6.13s\n",
      "30:\tlearn: 0.0522568\ttotal: 197ms\tremaining: 6.16s\n",
      "31:\tlearn: 0.0521360\ttotal: 204ms\tremaining: 6.18s\n",
      "32:\tlearn: 0.0520487\ttotal: 211ms\tremaining: 6.2s\n",
      "33:\tlearn: 0.0519533\ttotal: 219ms\tremaining: 6.22s\n",
      "34:\tlearn: 0.0518781\ttotal: 225ms\tremaining: 6.2s\n",
      "35:\tlearn: 0.0517884\ttotal: 230ms\tremaining: 6.17s\n",
      "36:\tlearn: 0.0517275\ttotal: 237ms\tremaining: 6.16s\n",
      "37:\tlearn: 0.0516800\ttotal: 244ms\tremaining: 6.18s\n",
      "38:\tlearn: 0.0516251\ttotal: 252ms\tremaining: 6.22s\n",
      "39:\tlearn: 0.0515699\ttotal: 257ms\tremaining: 6.17s\n",
      "40:\tlearn: 0.0514882\ttotal: 265ms\tremaining: 6.19s\n",
      "41:\tlearn: 0.0514376\ttotal: 270ms\tremaining: 6.16s\n",
      "42:\tlearn: 0.0513807\ttotal: 280ms\tremaining: 6.23s\n",
      "43:\tlearn: 0.0512905\ttotal: 288ms\tremaining: 6.25s\n",
      "44:\tlearn: 0.0512729\ttotal: 294ms\tremaining: 6.23s\n",
      "45:\tlearn: 0.0512497\ttotal: 298ms\tremaining: 6.19s\n",
      "46:\tlearn: 0.0512289\ttotal: 303ms\tremaining: 6.15s\n",
      "47:\tlearn: 0.0511638\ttotal: 310ms\tremaining: 6.15s\n",
      "48:\tlearn: 0.0511357\ttotal: 314ms\tremaining: 6.1s\n",
      "49:\tlearn: 0.0510337\ttotal: 322ms\tremaining: 6.12s\n",
      "50:\tlearn: 0.0510105\ttotal: 328ms\tremaining: 6.11s\n",
      "51:\tlearn: 0.0510083\ttotal: 335ms\tremaining: 6.11s\n",
      "52:\tlearn: 0.0509503\ttotal: 341ms\tremaining: 6.09s\n",
      "53:\tlearn: 0.0509243\ttotal: 351ms\tremaining: 6.15s\n",
      "54:\tlearn: 0.0509092\ttotal: 356ms\tremaining: 6.12s\n",
      "55:\tlearn: 0.0508972\ttotal: 364ms\tremaining: 6.13s\n",
      "56:\tlearn: 0.0508255\ttotal: 372ms\tremaining: 6.15s\n",
      "57:\tlearn: 0.0507835\ttotal: 382ms\tremaining: 6.21s\n",
      "58:\tlearn: 0.0507581\ttotal: 392ms\tremaining: 6.25s\n",
      "59:\tlearn: 0.0507196\ttotal: 400ms\tremaining: 6.26s\n",
      "60:\tlearn: 0.0506818\ttotal: 407ms\tremaining: 6.27s\n",
      "61:\tlearn: 0.0506801\ttotal: 410ms\tremaining: 6.2s\n",
      "62:\tlearn: 0.0506477\ttotal: 415ms\tremaining: 6.18s\n",
      "63:\tlearn: 0.0506122\ttotal: 420ms\tremaining: 6.15s\n",
      "64:\tlearn: 0.0506021\ttotal: 428ms\tremaining: 6.15s\n",
      "65:\tlearn: 0.0506021\ttotal: 432ms\tremaining: 6.11s\n",
      "66:\tlearn: 0.0505633\ttotal: 438ms\tremaining: 6.1s\n",
      "67:\tlearn: 0.0505269\ttotal: 445ms\tremaining: 6.1s\n",
      "68:\tlearn: 0.0504781\ttotal: 452ms\tremaining: 6.1s\n",
      "69:\tlearn: 0.0504713\ttotal: 458ms\tremaining: 6.09s\n",
      "70:\tlearn: 0.0504469\ttotal: 466ms\tremaining: 6.1s\n",
      "71:\tlearn: 0.0504311\ttotal: 471ms\tremaining: 6.07s\n",
      "72:\tlearn: 0.0504216\ttotal: 475ms\tremaining: 6.04s\n",
      "73:\tlearn: 0.0504121\ttotal: 483ms\tremaining: 6.04s\n",
      "74:\tlearn: 0.0503786\ttotal: 487ms\tremaining: 6.01s\n",
      "75:\tlearn: 0.0503729\ttotal: 494ms\tremaining: 6s\n",
      "76:\tlearn: 0.0503681\ttotal: 499ms\tremaining: 5.98s\n",
      "77:\tlearn: 0.0503429\ttotal: 504ms\tremaining: 5.96s\n",
      "78:\tlearn: 0.0503282\ttotal: 511ms\tremaining: 5.96s\n",
      "79:\tlearn: 0.0503267\ttotal: 514ms\tremaining: 5.91s\n",
      "80:\tlearn: 0.0503169\ttotal: 519ms\tremaining: 5.89s\n",
      "81:\tlearn: 0.0503168\ttotal: 522ms\tremaining: 5.84s\n",
      "82:\tlearn: 0.0503041\ttotal: 527ms\tremaining: 5.82s\n",
      "83:\tlearn: 0.0503036\ttotal: 532ms\tremaining: 5.8s\n",
      "84:\tlearn: 0.0502945\ttotal: 540ms\tremaining: 5.81s\n",
      "85:\tlearn: 0.0502824\ttotal: 548ms\tremaining: 5.83s\n",
      "86:\tlearn: 0.0502577\ttotal: 555ms\tremaining: 5.82s\n",
      "87:\tlearn: 0.0502570\ttotal: 560ms\tremaining: 5.8s\n",
      "88:\tlearn: 0.0502535\ttotal: 565ms\tremaining: 5.78s\n",
      "89:\tlearn: 0.0502533\ttotal: 568ms\tremaining: 5.74s\n",
      "90:\tlearn: 0.0502337\ttotal: 577ms\tremaining: 5.76s\n",
      "91:\tlearn: 0.0502191\ttotal: 584ms\tremaining: 5.76s\n",
      "92:\tlearn: 0.0502175\ttotal: 590ms\tremaining: 5.75s\n",
      "93:\tlearn: 0.0502175\ttotal: 592ms\tremaining: 5.71s\n",
      "94:\tlearn: 0.0502167\ttotal: 596ms\tremaining: 5.68s\n",
      "95:\tlearn: 0.0502094\ttotal: 601ms\tremaining: 5.66s\n",
      "96:\tlearn: 0.0501930\ttotal: 608ms\tremaining: 5.66s\n",
      "97:\tlearn: 0.0501770\ttotal: 614ms\tremaining: 5.65s\n",
      "98:\tlearn: 0.0501608\ttotal: 622ms\tremaining: 5.66s\n",
      "99:\tlearn: 0.0501515\ttotal: 626ms\tremaining: 5.64s\n",
      "100:\tlearn: 0.0501505\ttotal: 631ms\tremaining: 5.62s\n",
      "101:\tlearn: 0.0501394\ttotal: 637ms\tremaining: 5.61s\n",
      "102:\tlearn: 0.0501363\ttotal: 644ms\tremaining: 5.61s\n",
      "103:\tlearn: 0.0501320\ttotal: 649ms\tremaining: 5.59s\n",
      "104:\tlearn: 0.0501243\ttotal: 654ms\tremaining: 5.58s\n",
      "105:\tlearn: 0.0501088\ttotal: 660ms\tremaining: 5.57s\n",
      "106:\tlearn: 0.0500746\ttotal: 667ms\tremaining: 5.57s\n",
      "107:\tlearn: 0.0500384\ttotal: 672ms\tremaining: 5.55s\n",
      "108:\tlearn: 0.0500383\ttotal: 675ms\tremaining: 5.51s\n",
      "109:\tlearn: 0.0500143\ttotal: 681ms\tremaining: 5.51s\n",
      "110:\tlearn: 0.0500077\ttotal: 687ms\tremaining: 5.5s\n",
      "111:\tlearn: 0.0499967\ttotal: 692ms\tremaining: 5.48s\n",
      "112:\tlearn: 0.0499630\ttotal: 699ms\tremaining: 5.48s\n",
      "113:\tlearn: 0.0499512\ttotal: 703ms\tremaining: 5.47s\n",
      "114:\tlearn: 0.0499394\ttotal: 708ms\tremaining: 5.45s\n",
      "115:\tlearn: 0.0499299\ttotal: 715ms\tremaining: 5.45s\n",
      "116:\tlearn: 0.0498997\ttotal: 723ms\tremaining: 5.46s\n",
      "117:\tlearn: 0.0498979\ttotal: 729ms\tremaining: 5.45s\n",
      "118:\tlearn: 0.0498796\ttotal: 737ms\tremaining: 5.46s\n",
      "119:\tlearn: 0.0498152\ttotal: 745ms\tremaining: 5.46s\n",
      "120:\tlearn: 0.0498031\ttotal: 750ms\tremaining: 5.44s\n",
      "121:\tlearn: 0.0497924\ttotal: 760ms\tremaining: 5.47s\n",
      "122:\tlearn: 0.0497903\ttotal: 768ms\tremaining: 5.47s\n",
      "123:\tlearn: 0.0497675\ttotal: 773ms\tremaining: 5.46s\n",
      "124:\tlearn: 0.0497665\ttotal: 781ms\tremaining: 5.46s\n",
      "125:\tlearn: 0.0497624\ttotal: 786ms\tremaining: 5.45s\n",
      "126:\tlearn: 0.0497516\ttotal: 793ms\tremaining: 5.45s\n",
      "127:\tlearn: 0.0497433\ttotal: 800ms\tremaining: 5.45s\n",
      "128:\tlearn: 0.0497430\ttotal: 805ms\tremaining: 5.43s\n",
      "129:\tlearn: 0.0497361\ttotal: 811ms\tremaining: 5.42s\n",
      "130:\tlearn: 0.0497282\ttotal: 818ms\tremaining: 5.42s\n",
      "131:\tlearn: 0.0496985\ttotal: 825ms\tremaining: 5.42s\n",
      "132:\tlearn: 0.0496975\ttotal: 830ms\tremaining: 5.41s\n",
      "133:\tlearn: 0.0496689\ttotal: 839ms\tremaining: 5.42s\n",
      "134:\tlearn: 0.0496526\ttotal: 844ms\tremaining: 5.4s\n",
      "135:\tlearn: 0.0496472\ttotal: 851ms\tremaining: 5.41s\n",
      "136:\tlearn: 0.0496332\ttotal: 858ms\tremaining: 5.41s\n",
      "137:\tlearn: 0.0495941\ttotal: 867ms\tremaining: 5.42s\n",
      "138:\tlearn: 0.0495473\ttotal: 878ms\tremaining: 5.44s\n",
      "139:\tlearn: 0.0495421\ttotal: 883ms\tremaining: 5.42s\n",
      "140:\tlearn: 0.0495266\ttotal: 891ms\tremaining: 5.43s\n",
      "141:\tlearn: 0.0495257\ttotal: 896ms\tremaining: 5.41s\n",
      "142:\tlearn: 0.0495252\ttotal: 902ms\tremaining: 5.4s\n",
      "143:\tlearn: 0.0495251\ttotal: 905ms\tremaining: 5.38s\n",
      "144:\tlearn: 0.0495170\ttotal: 914ms\tremaining: 5.39s\n",
      "145:\tlearn: 0.0495152\ttotal: 923ms\tremaining: 5.4s\n",
      "146:\tlearn: 0.0495104\ttotal: 928ms\tremaining: 5.38s\n",
      "147:\tlearn: 0.0495036\ttotal: 933ms\tremaining: 5.37s\n",
      "148:\tlearn: 0.0494999\ttotal: 943ms\tremaining: 5.38s\n",
      "149:\tlearn: 0.0494872\ttotal: 952ms\tremaining: 5.39s\n",
      "150:\tlearn: 0.0494851\ttotal: 959ms\tremaining: 5.39s\n",
      "151:\tlearn: 0.0494849\ttotal: 964ms\tremaining: 5.38s\n",
      "152:\tlearn: 0.0494816\ttotal: 968ms\tremaining: 5.36s\n",
      "153:\tlearn: 0.0494815\ttotal: 971ms\tremaining: 5.33s\n",
      "154:\tlearn: 0.0494446\ttotal: 978ms\tremaining: 5.33s\n",
      "155:\tlearn: 0.0494430\ttotal: 983ms\tremaining: 5.32s\n",
      "156:\tlearn: 0.0494303\ttotal: 989ms\tremaining: 5.31s\n",
      "157:\tlearn: 0.0494167\ttotal: 996ms\tremaining: 5.31s\n",
      "158:\tlearn: 0.0494083\ttotal: 1s\tremaining: 5.29s\n",
      "159:\tlearn: 0.0493847\ttotal: 1.01s\tremaining: 5.29s\n",
      "160:\tlearn: 0.0493846\ttotal: 1.01s\tremaining: 5.28s\n",
      "161:\tlearn: 0.0493823\ttotal: 1.02s\tremaining: 5.27s\n",
      "162:\tlearn: 0.0493773\ttotal: 1.03s\tremaining: 5.27s\n",
      "163:\tlearn: 0.0493559\ttotal: 1.03s\tremaining: 5.26s\n",
      "164:\tlearn: 0.0493537\ttotal: 1.04s\tremaining: 5.25s\n",
      "165:\tlearn: 0.0493534\ttotal: 1.04s\tremaining: 5.23s\n",
      "166:\tlearn: 0.0493327\ttotal: 1.05s\tremaining: 5.23s\n",
      "167:\tlearn: 0.0493285\ttotal: 1.05s\tremaining: 5.22s\n",
      "168:\tlearn: 0.0493057\ttotal: 1.06s\tremaining: 5.23s\n",
      "169:\tlearn: 0.0492868\ttotal: 1.07s\tremaining: 5.22s\n",
      "170:\tlearn: 0.0492642\ttotal: 1.08s\tremaining: 5.22s\n",
      "171:\tlearn: 0.0492638\ttotal: 1.08s\tremaining: 5.21s\n",
      "172:\tlearn: 0.0492590\ttotal: 1.09s\tremaining: 5.2s\n",
      "173:\tlearn: 0.0492556\ttotal: 1.09s\tremaining: 5.19s\n",
      "174:\tlearn: 0.0492532\ttotal: 1.1s\tremaining: 5.18s\n",
      "175:\tlearn: 0.0492532\ttotal: 1.1s\tremaining: 5.16s\n",
      "176:\tlearn: 0.0492420\ttotal: 1.11s\tremaining: 5.16s\n",
      "177:\tlearn: 0.0492304\ttotal: 1.12s\tremaining: 5.16s\n",
      "178:\tlearn: 0.0492222\ttotal: 1.12s\tremaining: 5.15s\n",
      "179:\tlearn: 0.0492221\ttotal: 1.13s\tremaining: 5.13s\n",
      "180:\tlearn: 0.0492214\ttotal: 1.13s\tremaining: 5.12s\n",
      "181:\tlearn: 0.0492018\ttotal: 1.14s\tremaining: 5.14s\n",
      "182:\tlearn: 0.0492012\ttotal: 1.15s\tremaining: 5.13s\n",
      "183:\tlearn: 0.0491806\ttotal: 1.16s\tremaining: 5.14s\n",
      "184:\tlearn: 0.0491768\ttotal: 1.16s\tremaining: 5.12s\n",
      "185:\tlearn: 0.0491754\ttotal: 1.17s\tremaining: 5.11s\n",
      "186:\tlearn: 0.0491575\ttotal: 1.18s\tremaining: 5.11s\n",
      "187:\tlearn: 0.0491552\ttotal: 1.18s\tremaining: 5.1s\n",
      "188:\tlearn: 0.0491364\ttotal: 1.19s\tremaining: 5.08s\n",
      "189:\tlearn: 0.0491244\ttotal: 1.19s\tremaining: 5.09s\n",
      "190:\tlearn: 0.0491041\ttotal: 1.2s\tremaining: 5.09s\n",
      "191:\tlearn: 0.0490938\ttotal: 1.21s\tremaining: 5.09s\n",
      "192:\tlearn: 0.0490625\ttotal: 1.22s\tremaining: 5.09s\n",
      "193:\tlearn: 0.0490571\ttotal: 1.23s\tremaining: 5.1s\n",
      "194:\tlearn: 0.0490562\ttotal: 1.23s\tremaining: 5.08s\n",
      "195:\tlearn: 0.0490455\ttotal: 1.24s\tremaining: 5.09s\n",
      "196:\tlearn: 0.0490439\ttotal: 1.25s\tremaining: 5.08s\n",
      "197:\tlearn: 0.0490414\ttotal: 1.25s\tremaining: 5.08s\n",
      "198:\tlearn: 0.0490413\ttotal: 1.26s\tremaining: 5.07s\n",
      "199:\tlearn: 0.0490411\ttotal: 1.26s\tremaining: 5.05s\n",
      "200:\tlearn: 0.0490367\ttotal: 1.27s\tremaining: 5.06s\n",
      "201:\tlearn: 0.0490357\ttotal: 1.28s\tremaining: 5.05s\n",
      "202:\tlearn: 0.0490302\ttotal: 1.28s\tremaining: 5.04s\n",
      "203:\tlearn: 0.0490180\ttotal: 1.29s\tremaining: 5.03s\n",
      "204:\tlearn: 0.0490177\ttotal: 1.29s\tremaining: 5.02s\n",
      "205:\tlearn: 0.0490176\ttotal: 1.3s\tremaining: 5.01s\n",
      "206:\tlearn: 0.0490001\ttotal: 1.3s\tremaining: 5s\n",
      "207:\tlearn: 0.0489729\ttotal: 1.31s\tremaining: 4.99s\n",
      "208:\tlearn: 0.0489718\ttotal: 1.32s\tremaining: 4.99s\n",
      "209:\tlearn: 0.0489483\ttotal: 1.33s\tremaining: 4.99s\n",
      "210:\tlearn: 0.0489479\ttotal: 1.33s\tremaining: 4.98s\n",
      "211:\tlearn: 0.0489407\ttotal: 1.34s\tremaining: 4.98s\n",
      "212:\tlearn: 0.0489391\ttotal: 1.35s\tremaining: 4.98s\n",
      "213:\tlearn: 0.0489218\ttotal: 1.36s\tremaining: 4.99s\n",
      "214:\tlearn: 0.0489209\ttotal: 1.36s\tremaining: 4.98s\n",
      "215:\tlearn: 0.0489087\ttotal: 1.37s\tremaining: 4.98s\n",
      "216:\tlearn: 0.0488919\ttotal: 1.38s\tremaining: 4.98s\n",
      "217:\tlearn: 0.0488848\ttotal: 1.39s\tremaining: 4.98s\n",
      "218:\tlearn: 0.0488729\ttotal: 1.4s\tremaining: 4.98s\n",
      "219:\tlearn: 0.0488643\ttotal: 1.41s\tremaining: 4.98s\n",
      "220:\tlearn: 0.0488464\ttotal: 1.41s\tremaining: 4.98s\n",
      "221:\tlearn: 0.0488456\ttotal: 1.42s\tremaining: 4.98s\n",
      "222:\tlearn: 0.0488454\ttotal: 1.42s\tremaining: 4.96s\n",
      "223:\tlearn: 0.0488085\ttotal: 1.43s\tremaining: 4.96s\n",
      "224:\tlearn: 0.0487962\ttotal: 1.44s\tremaining: 4.97s\n",
      "225:\tlearn: 0.0487924\ttotal: 1.45s\tremaining: 4.97s\n",
      "226:\tlearn: 0.0487678\ttotal: 1.46s\tremaining: 4.97s\n",
      "227:\tlearn: 0.0487647\ttotal: 1.47s\tremaining: 4.96s\n",
      "228:\tlearn: 0.0487625\ttotal: 1.47s\tremaining: 4.96s\n",
      "229:\tlearn: 0.0487618\ttotal: 1.48s\tremaining: 4.95s\n",
      "230:\tlearn: 0.0487459\ttotal: 1.49s\tremaining: 4.95s\n",
      "231:\tlearn: 0.0487438\ttotal: 1.49s\tremaining: 4.94s\n",
      "232:\tlearn: 0.0487436\ttotal: 1.5s\tremaining: 4.93s\n",
      "233:\tlearn: 0.0487389\ttotal: 1.51s\tremaining: 4.93s\n",
      "234:\tlearn: 0.0487387\ttotal: 1.51s\tremaining: 4.91s\n",
      "235:\tlearn: 0.0487323\ttotal: 1.51s\tremaining: 4.91s\n",
      "236:\tlearn: 0.0487120\ttotal: 1.52s\tremaining: 4.91s\n",
      "237:\tlearn: 0.0487015\ttotal: 1.53s\tremaining: 4.9s\n",
      "238:\tlearn: 0.0486997\ttotal: 1.54s\tremaining: 4.9s\n",
      "239:\tlearn: 0.0486959\ttotal: 1.54s\tremaining: 4.89s\n",
      "240:\tlearn: 0.0486774\ttotal: 1.56s\tremaining: 4.9s\n",
      "241:\tlearn: 0.0486764\ttotal: 1.56s\tremaining: 4.9s\n",
      "242:\tlearn: 0.0486655\ttotal: 1.57s\tremaining: 4.9s\n",
      "243:\tlearn: 0.0486572\ttotal: 1.58s\tremaining: 4.89s\n",
      "244:\tlearn: 0.0486566\ttotal: 1.59s\tremaining: 4.89s\n",
      "245:\tlearn: 0.0486333\ttotal: 1.6s\tremaining: 4.89s\n",
      "246:\tlearn: 0.0486331\ttotal: 1.6s\tremaining: 4.89s\n",
      "247:\tlearn: 0.0486255\ttotal: 1.61s\tremaining: 4.89s\n",
      "248:\tlearn: 0.0486148\ttotal: 1.62s\tremaining: 4.88s\n",
      "249:\tlearn: 0.0485872\ttotal: 1.63s\tremaining: 4.89s\n",
      "250:\tlearn: 0.0485741\ttotal: 1.64s\tremaining: 4.89s\n",
      "251:\tlearn: 0.0485523\ttotal: 1.65s\tremaining: 4.9s\n",
      "252:\tlearn: 0.0485506\ttotal: 1.66s\tremaining: 4.9s\n",
      "253:\tlearn: 0.0485327\ttotal: 1.67s\tremaining: 4.9s\n",
      "254:\tlearn: 0.0485214\ttotal: 1.67s\tremaining: 4.89s\n",
      "255:\tlearn: 0.0485123\ttotal: 1.68s\tremaining: 4.88s\n",
      "256:\tlearn: 0.0485092\ttotal: 1.69s\tremaining: 4.88s\n",
      "257:\tlearn: 0.0484838\ttotal: 1.7s\tremaining: 4.88s\n",
      "258:\tlearn: 0.0484771\ttotal: 1.7s\tremaining: 4.87s\n",
      "259:\tlearn: 0.0484437\ttotal: 1.71s\tremaining: 4.87s\n",
      "260:\tlearn: 0.0484428\ttotal: 1.72s\tremaining: 4.86s\n",
      "261:\tlearn: 0.0484379\ttotal: 1.73s\tremaining: 4.87s\n",
      "262:\tlearn: 0.0484377\ttotal: 1.74s\tremaining: 4.86s\n",
      "263:\tlearn: 0.0484265\ttotal: 1.74s\tremaining: 4.86s\n",
      "264:\tlearn: 0.0484104\ttotal: 1.75s\tremaining: 4.85s\n",
      "265:\tlearn: 0.0484090\ttotal: 1.76s\tremaining: 4.85s\n",
      "266:\tlearn: 0.0484082\ttotal: 1.76s\tremaining: 4.84s\n",
      "267:\tlearn: 0.0484024\ttotal: 1.77s\tremaining: 4.83s\n",
      "268:\tlearn: 0.0484009\ttotal: 1.78s\tremaining: 4.83s\n",
      "269:\tlearn: 0.0483859\ttotal: 1.79s\tremaining: 4.83s\n",
      "270:\tlearn: 0.0483858\ttotal: 1.79s\tremaining: 4.82s\n",
      "271:\tlearn: 0.0483857\ttotal: 1.79s\tremaining: 4.81s\n",
      "272:\tlearn: 0.0483798\ttotal: 1.8s\tremaining: 4.79s\n",
      "273:\tlearn: 0.0483722\ttotal: 1.81s\tremaining: 4.79s\n",
      "274:\tlearn: 0.0483660\ttotal: 1.81s\tremaining: 4.78s\n",
      "275:\tlearn: 0.0483339\ttotal: 1.82s\tremaining: 4.78s\n",
      "276:\tlearn: 0.0483284\ttotal: 1.83s\tremaining: 4.77s\n",
      "277:\tlearn: 0.0483284\ttotal: 1.83s\tremaining: 4.76s\n",
      "278:\tlearn: 0.0483058\ttotal: 1.84s\tremaining: 4.76s\n",
      "279:\tlearn: 0.0482897\ttotal: 1.85s\tremaining: 4.75s\n",
      "280:\tlearn: 0.0482846\ttotal: 1.86s\tremaining: 4.75s\n",
      "281:\tlearn: 0.0482737\ttotal: 1.86s\tremaining: 4.75s\n",
      "282:\tlearn: 0.0482726\ttotal: 1.87s\tremaining: 4.74s\n",
      "283:\tlearn: 0.0482719\ttotal: 1.88s\tremaining: 4.73s\n",
      "284:\tlearn: 0.0482617\ttotal: 1.89s\tremaining: 4.73s\n",
      "285:\tlearn: 0.0482479\ttotal: 1.9s\tremaining: 4.73s\n",
      "286:\tlearn: 0.0482438\ttotal: 1.9s\tremaining: 4.73s\n",
      "287:\tlearn: 0.0482382\ttotal: 1.91s\tremaining: 4.72s\n",
      "288:\tlearn: 0.0482381\ttotal: 1.92s\tremaining: 4.72s\n",
      "289:\tlearn: 0.0482124\ttotal: 1.92s\tremaining: 4.71s\n",
      "290:\tlearn: 0.0482118\ttotal: 1.93s\tremaining: 4.71s\n",
      "291:\tlearn: 0.0482017\ttotal: 1.94s\tremaining: 4.7s\n",
      "292:\tlearn: 0.0481996\ttotal: 1.94s\tremaining: 4.69s\n",
      "293:\tlearn: 0.0481868\ttotal: 1.95s\tremaining: 4.68s\n",
      "294:\tlearn: 0.0481694\ttotal: 1.96s\tremaining: 4.68s\n",
      "295:\tlearn: 0.0481687\ttotal: 1.96s\tremaining: 4.67s\n",
      "296:\tlearn: 0.0481478\ttotal: 1.97s\tremaining: 4.67s\n",
      "297:\tlearn: 0.0481436\ttotal: 1.98s\tremaining: 4.67s\n",
      "298:\tlearn: 0.0481383\ttotal: 1.99s\tremaining: 4.67s\n",
      "299:\tlearn: 0.0481382\ttotal: 2s\tremaining: 4.66s\n",
      "300:\tlearn: 0.0481281\ttotal: 2.01s\tremaining: 4.66s\n",
      "301:\tlearn: 0.0481096\ttotal: 2.02s\tremaining: 4.66s\n",
      "302:\tlearn: 0.0481048\ttotal: 2.02s\tremaining: 4.66s\n",
      "303:\tlearn: 0.0480853\ttotal: 2.03s\tremaining: 4.65s\n",
      "304:\tlearn: 0.0480645\ttotal: 2.04s\tremaining: 4.65s\n",
      "305:\tlearn: 0.0480563\ttotal: 2.05s\tremaining: 4.65s\n",
      "306:\tlearn: 0.0480517\ttotal: 2.05s\tremaining: 4.64s\n",
      "307:\tlearn: 0.0480430\ttotal: 2.06s\tremaining: 4.63s\n",
      "308:\tlearn: 0.0480383\ttotal: 2.07s\tremaining: 4.63s\n",
      "309:\tlearn: 0.0480340\ttotal: 2.07s\tremaining: 4.62s\n",
      "310:\tlearn: 0.0480339\ttotal: 2.08s\tremaining: 4.61s\n",
      "311:\tlearn: 0.0480276\ttotal: 2.08s\tremaining: 4.6s\n",
      "312:\tlearn: 0.0480275\ttotal: 2.09s\tremaining: 4.59s\n",
      "313:\tlearn: 0.0480089\ttotal: 2.1s\tremaining: 4.59s\n",
      "314:\tlearn: 0.0480021\ttotal: 2.11s\tremaining: 4.58s\n",
      "315:\tlearn: 0.0479979\ttotal: 2.11s\tremaining: 4.57s\n",
      "316:\tlearn: 0.0479892\ttotal: 2.12s\tremaining: 4.57s\n",
      "317:\tlearn: 0.0479814\ttotal: 2.13s\tremaining: 4.57s\n",
      "318:\tlearn: 0.0479687\ttotal: 2.14s\tremaining: 4.57s\n",
      "319:\tlearn: 0.0479514\ttotal: 2.15s\tremaining: 4.57s\n",
      "320:\tlearn: 0.0479389\ttotal: 2.16s\tremaining: 4.57s\n",
      "321:\tlearn: 0.0479379\ttotal: 2.17s\tremaining: 4.57s\n",
      "322:\tlearn: 0.0479253\ttotal: 2.18s\tremaining: 4.56s\n",
      "323:\tlearn: 0.0479095\ttotal: 2.18s\tremaining: 4.56s\n",
      "324:\tlearn: 0.0479028\ttotal: 2.19s\tremaining: 4.55s\n",
      "325:\tlearn: 0.0479017\ttotal: 2.2s\tremaining: 4.55s\n",
      "326:\tlearn: 0.0478885\ttotal: 2.21s\tremaining: 4.55s\n",
      "327:\tlearn: 0.0478858\ttotal: 2.21s\tremaining: 4.54s\n",
      "328:\tlearn: 0.0478704\ttotal: 2.23s\tremaining: 4.54s\n",
      "329:\tlearn: 0.0478628\ttotal: 2.24s\tremaining: 4.54s\n",
      "330:\tlearn: 0.0478533\ttotal: 2.25s\tremaining: 4.54s\n",
      "331:\tlearn: 0.0478353\ttotal: 2.26s\tremaining: 4.54s\n",
      "332:\tlearn: 0.0478320\ttotal: 2.27s\tremaining: 4.54s\n",
      "333:\tlearn: 0.0478029\ttotal: 2.27s\tremaining: 4.54s\n",
      "334:\tlearn: 0.0477892\ttotal: 2.28s\tremaining: 4.53s\n",
      "335:\tlearn: 0.0477822\ttotal: 2.29s\tremaining: 4.53s\n",
      "336:\tlearn: 0.0477713\ttotal: 2.3s\tremaining: 4.52s\n",
      "337:\tlearn: 0.0477670\ttotal: 2.3s\tremaining: 4.51s\n",
      "338:\tlearn: 0.0477647\ttotal: 2.31s\tremaining: 4.51s\n",
      "339:\tlearn: 0.0477187\ttotal: 2.32s\tremaining: 4.51s\n",
      "340:\tlearn: 0.0477015\ttotal: 2.33s\tremaining: 4.51s\n",
      "341:\tlearn: 0.0476944\ttotal: 2.34s\tremaining: 4.5s\n",
      "342:\tlearn: 0.0476908\ttotal: 2.35s\tremaining: 4.5s\n",
      "343:\tlearn: 0.0476851\ttotal: 2.36s\tremaining: 4.49s\n",
      "344:\tlearn: 0.0476766\ttotal: 2.36s\tremaining: 4.49s\n",
      "345:\tlearn: 0.0476611\ttotal: 2.37s\tremaining: 4.48s\n",
      "346:\tlearn: 0.0476505\ttotal: 2.37s\tremaining: 4.47s\n",
      "347:\tlearn: 0.0476475\ttotal: 2.38s\tremaining: 4.46s\n",
      "348:\tlearn: 0.0476448\ttotal: 2.39s\tremaining: 4.46s\n",
      "349:\tlearn: 0.0476242\ttotal: 2.4s\tremaining: 4.45s\n",
      "350:\tlearn: 0.0476137\ttotal: 2.4s\tremaining: 4.45s\n",
      "351:\tlearn: 0.0476113\ttotal: 2.41s\tremaining: 4.44s\n",
      "352:\tlearn: 0.0476034\ttotal: 2.42s\tremaining: 4.43s\n",
      "353:\tlearn: 0.0475985\ttotal: 2.42s\tremaining: 4.42s\n",
      "354:\tlearn: 0.0475886\ttotal: 2.43s\tremaining: 4.41s\n",
      "355:\tlearn: 0.0475747\ttotal: 2.43s\tremaining: 4.4s\n",
      "356:\tlearn: 0.0475714\ttotal: 2.44s\tremaining: 4.39s\n",
      "357:\tlearn: 0.0475545\ttotal: 2.45s\tremaining: 4.39s\n",
      "358:\tlearn: 0.0475482\ttotal: 2.45s\tremaining: 4.38s\n",
      "359:\tlearn: 0.0475350\ttotal: 2.46s\tremaining: 4.37s\n",
      "360:\tlearn: 0.0475343\ttotal: 2.47s\tremaining: 4.37s\n",
      "361:\tlearn: 0.0475267\ttotal: 2.48s\tremaining: 4.36s\n",
      "362:\tlearn: 0.0475141\ttotal: 2.48s\tremaining: 4.36s\n",
      "363:\tlearn: 0.0475016\ttotal: 2.49s\tremaining: 4.35s\n",
      "364:\tlearn: 0.0474950\ttotal: 2.5s\tremaining: 4.35s\n",
      "365:\tlearn: 0.0474782\ttotal: 2.51s\tremaining: 4.34s\n",
      "366:\tlearn: 0.0474675\ttotal: 2.52s\tremaining: 4.34s\n",
      "367:\tlearn: 0.0474645\ttotal: 2.52s\tremaining: 4.33s\n",
      "368:\tlearn: 0.0474623\ttotal: 2.53s\tremaining: 4.32s\n",
      "369:\tlearn: 0.0474584\ttotal: 2.54s\tremaining: 4.32s\n",
      "370:\tlearn: 0.0474554\ttotal: 2.55s\tremaining: 4.32s\n",
      "371:\tlearn: 0.0474503\ttotal: 2.55s\tremaining: 4.31s\n",
      "372:\tlearn: 0.0474440\ttotal: 2.56s\tremaining: 4.31s\n",
      "373:\tlearn: 0.0474412\ttotal: 2.57s\tremaining: 4.3s\n",
      "374:\tlearn: 0.0474388\ttotal: 2.58s\tremaining: 4.29s\n",
      "375:\tlearn: 0.0474178\ttotal: 2.59s\tremaining: 4.3s\n",
      "376:\tlearn: 0.0474155\ttotal: 2.6s\tremaining: 4.29s\n",
      "377:\tlearn: 0.0474082\ttotal: 2.6s\tremaining: 4.28s\n",
      "378:\tlearn: 0.0473951\ttotal: 2.61s\tremaining: 4.28s\n",
      "379:\tlearn: 0.0473946\ttotal: 2.62s\tremaining: 4.27s\n",
      "380:\tlearn: 0.0473935\ttotal: 2.63s\tremaining: 4.26s\n",
      "381:\tlearn: 0.0473885\ttotal: 2.63s\tremaining: 4.26s\n",
      "382:\tlearn: 0.0473725\ttotal: 2.64s\tremaining: 4.26s\n",
      "383:\tlearn: 0.0473521\ttotal: 2.65s\tremaining: 4.25s\n",
      "384:\tlearn: 0.0473295\ttotal: 2.66s\tremaining: 4.25s\n",
      "385:\tlearn: 0.0473207\ttotal: 2.67s\tremaining: 4.24s\n",
      "386:\tlearn: 0.0473167\ttotal: 2.68s\tremaining: 4.24s\n",
      "387:\tlearn: 0.0473079\ttotal: 2.69s\tremaining: 4.24s\n",
      "388:\tlearn: 0.0472992\ttotal: 2.69s\tremaining: 4.23s\n",
      "389:\tlearn: 0.0472915\ttotal: 2.7s\tremaining: 4.23s\n",
      "390:\tlearn: 0.0472869\ttotal: 2.71s\tremaining: 4.22s\n",
      "391:\tlearn: 0.0472869\ttotal: 2.72s\tremaining: 4.21s\n",
      "392:\tlearn: 0.0472850\ttotal: 2.73s\tremaining: 4.21s\n",
      "393:\tlearn: 0.0472840\ttotal: 2.73s\tremaining: 4.2s\n",
      "394:\tlearn: 0.0472831\ttotal: 2.74s\tremaining: 4.2s\n",
      "395:\tlearn: 0.0472828\ttotal: 2.75s\tremaining: 4.19s\n",
      "396:\tlearn: 0.0472688\ttotal: 2.76s\tremaining: 4.19s\n",
      "397:\tlearn: 0.0472666\ttotal: 2.76s\tremaining: 4.17s\n",
      "398:\tlearn: 0.0472665\ttotal: 2.76s\tremaining: 4.16s\n",
      "399:\tlearn: 0.0472630\ttotal: 2.77s\tremaining: 4.16s\n",
      "400:\tlearn: 0.0472569\ttotal: 2.78s\tremaining: 4.15s\n",
      "401:\tlearn: 0.0472349\ttotal: 2.79s\tremaining: 4.15s\n",
      "402:\tlearn: 0.0472280\ttotal: 2.79s\tremaining: 4.14s\n",
      "403:\tlearn: 0.0472170\ttotal: 2.8s\tremaining: 4.13s\n",
      "404:\tlearn: 0.0472026\ttotal: 2.81s\tremaining: 4.13s\n",
      "405:\tlearn: 0.0471944\ttotal: 2.82s\tremaining: 4.13s\n",
      "406:\tlearn: 0.0471879\ttotal: 2.83s\tremaining: 4.12s\n",
      "407:\tlearn: 0.0471839\ttotal: 2.84s\tremaining: 4.12s\n",
      "408:\tlearn: 0.0471831\ttotal: 2.85s\tremaining: 4.11s\n",
      "409:\tlearn: 0.0471725\ttotal: 2.85s\tremaining: 4.11s\n",
      "410:\tlearn: 0.0471619\ttotal: 2.86s\tremaining: 4.1s\n",
      "411:\tlearn: 0.0471605\ttotal: 2.87s\tremaining: 4.1s\n",
      "412:\tlearn: 0.0471543\ttotal: 2.88s\tremaining: 4.09s\n",
      "413:\tlearn: 0.0471529\ttotal: 2.89s\tremaining: 4.09s\n",
      "414:\tlearn: 0.0471521\ttotal: 2.9s\tremaining: 4.08s\n",
      "415:\tlearn: 0.0471417\ttotal: 2.9s\tremaining: 4.08s\n",
      "416:\tlearn: 0.0471254\ttotal: 2.91s\tremaining: 4.07s\n",
      "417:\tlearn: 0.0471121\ttotal: 2.92s\tremaining: 4.07s\n",
      "418:\tlearn: 0.0471015\ttotal: 2.93s\tremaining: 4.07s\n",
      "419:\tlearn: 0.0470868\ttotal: 2.94s\tremaining: 4.06s\n",
      "420:\tlearn: 0.0470746\ttotal: 2.95s\tremaining: 4.05s\n",
      "421:\tlearn: 0.0470729\ttotal: 2.96s\tremaining: 4.05s\n",
      "422:\tlearn: 0.0470526\ttotal: 2.96s\tremaining: 4.04s\n",
      "423:\tlearn: 0.0470433\ttotal: 2.97s\tremaining: 4.04s\n",
      "424:\tlearn: 0.0470301\ttotal: 2.98s\tremaining: 4.03s\n",
      "425:\tlearn: 0.0470233\ttotal: 2.98s\tremaining: 4.02s\n",
      "426:\tlearn: 0.0470070\ttotal: 2.99s\tremaining: 4.01s\n",
      "427:\tlearn: 0.0470006\ttotal: 3s\tremaining: 4.01s\n",
      "428:\tlearn: 0.0469987\ttotal: 3s\tremaining: 4s\n",
      "429:\tlearn: 0.0469979\ttotal: 3.01s\tremaining: 3.99s\n",
      "430:\tlearn: 0.0469960\ttotal: 3.01s\tremaining: 3.98s\n",
      "431:\tlearn: 0.0469826\ttotal: 3.02s\tremaining: 3.97s\n",
      "432:\tlearn: 0.0469776\ttotal: 3.03s\tremaining: 3.97s\n",
      "433:\tlearn: 0.0469701\ttotal: 3.04s\tremaining: 3.96s\n",
      "434:\tlearn: 0.0469610\ttotal: 3.04s\tremaining: 3.95s\n",
      "435:\tlearn: 0.0469603\ttotal: 3.05s\tremaining: 3.95s\n",
      "436:\tlearn: 0.0469377\ttotal: 3.06s\tremaining: 3.94s\n",
      "437:\tlearn: 0.0469365\ttotal: 3.06s\tremaining: 3.93s\n",
      "438:\tlearn: 0.0469243\ttotal: 3.07s\tremaining: 3.93s\n",
      "439:\tlearn: 0.0469180\ttotal: 3.08s\tremaining: 3.92s\n",
      "440:\tlearn: 0.0469109\ttotal: 3.09s\tremaining: 3.92s\n",
      "441:\tlearn: 0.0469100\ttotal: 3.1s\tremaining: 3.91s\n",
      "442:\tlearn: 0.0469008\ttotal: 3.1s\tremaining: 3.9s\n",
      "443:\tlearn: 0.0468963\ttotal: 3.11s\tremaining: 3.89s\n",
      "444:\tlearn: 0.0468920\ttotal: 3.12s\tremaining: 3.89s\n",
      "445:\tlearn: 0.0468682\ttotal: 3.13s\tremaining: 3.88s\n",
      "446:\tlearn: 0.0468646\ttotal: 3.14s\tremaining: 3.88s\n",
      "447:\tlearn: 0.0468625\ttotal: 3.14s\tremaining: 3.87s\n",
      "448:\tlearn: 0.0468543\ttotal: 3.15s\tremaining: 3.87s\n",
      "449:\tlearn: 0.0468528\ttotal: 3.16s\tremaining: 3.86s\n",
      "450:\tlearn: 0.0468417\ttotal: 3.17s\tremaining: 3.85s\n",
      "451:\tlearn: 0.0468355\ttotal: 3.17s\tremaining: 3.85s\n",
      "452:\tlearn: 0.0468244\ttotal: 3.18s\tremaining: 3.84s\n",
      "453:\tlearn: 0.0468237\ttotal: 3.19s\tremaining: 3.83s\n",
      "454:\tlearn: 0.0468166\ttotal: 3.2s\tremaining: 3.83s\n",
      "455:\tlearn: 0.0468073\ttotal: 3.2s\tremaining: 3.82s\n",
      "456:\tlearn: 0.0467995\ttotal: 3.21s\tremaining: 3.81s\n",
      "457:\tlearn: 0.0467890\ttotal: 3.22s\tremaining: 3.81s\n",
      "458:\tlearn: 0.0467842\ttotal: 3.22s\tremaining: 3.8s\n",
      "459:\tlearn: 0.0467737\ttotal: 3.23s\tremaining: 3.79s\n",
      "460:\tlearn: 0.0467554\ttotal: 3.24s\tremaining: 3.79s\n",
      "461:\tlearn: 0.0467370\ttotal: 3.25s\tremaining: 3.78s\n",
      "462:\tlearn: 0.0467254\ttotal: 3.26s\tremaining: 3.78s\n",
      "463:\tlearn: 0.0467187\ttotal: 3.26s\tremaining: 3.77s\n",
      "464:\tlearn: 0.0467182\ttotal: 3.27s\tremaining: 3.76s\n",
      "465:\tlearn: 0.0467011\ttotal: 3.28s\tremaining: 3.76s\n",
      "466:\tlearn: 0.0466971\ttotal: 3.28s\tremaining: 3.75s\n",
      "467:\tlearn: 0.0466904\ttotal: 3.29s\tremaining: 3.74s\n",
      "468:\tlearn: 0.0466879\ttotal: 3.3s\tremaining: 3.74s\n",
      "469:\tlearn: 0.0466871\ttotal: 3.31s\tremaining: 3.73s\n",
      "470:\tlearn: 0.0466777\ttotal: 3.32s\tremaining: 3.73s\n",
      "471:\tlearn: 0.0466733\ttotal: 3.33s\tremaining: 3.72s\n",
      "472:\tlearn: 0.0466661\ttotal: 3.34s\tremaining: 3.72s\n",
      "473:\tlearn: 0.0466653\ttotal: 3.34s\tremaining: 3.71s\n",
      "474:\tlearn: 0.0466647\ttotal: 3.35s\tremaining: 3.7s\n",
      "475:\tlearn: 0.0466489\ttotal: 3.36s\tremaining: 3.7s\n",
      "476:\tlearn: 0.0466479\ttotal: 3.37s\tremaining: 3.69s\n",
      "477:\tlearn: 0.0466339\ttotal: 3.37s\tremaining: 3.68s\n",
      "478:\tlearn: 0.0466257\ttotal: 3.38s\tremaining: 3.68s\n",
      "479:\tlearn: 0.0466194\ttotal: 3.39s\tremaining: 3.67s\n",
      "480:\tlearn: 0.0465986\ttotal: 3.4s\tremaining: 3.66s\n",
      "481:\tlearn: 0.0465912\ttotal: 3.4s\tremaining: 3.66s\n",
      "482:\tlearn: 0.0465890\ttotal: 3.41s\tremaining: 3.65s\n",
      "483:\tlearn: 0.0465861\ttotal: 3.41s\tremaining: 3.64s\n",
      "484:\tlearn: 0.0465853\ttotal: 3.42s\tremaining: 3.63s\n",
      "485:\tlearn: 0.0465838\ttotal: 3.43s\tremaining: 3.63s\n",
      "486:\tlearn: 0.0465711\ttotal: 3.44s\tremaining: 3.63s\n",
      "487:\tlearn: 0.0465693\ttotal: 3.45s\tremaining: 3.62s\n",
      "488:\tlearn: 0.0465548\ttotal: 3.46s\tremaining: 3.62s\n",
      "489:\tlearn: 0.0465541\ttotal: 3.47s\tremaining: 3.61s\n",
      "490:\tlearn: 0.0465253\ttotal: 3.48s\tremaining: 3.61s\n",
      "491:\tlearn: 0.0465211\ttotal: 3.49s\tremaining: 3.6s\n",
      "492:\tlearn: 0.0465163\ttotal: 3.49s\tremaining: 3.59s\n",
      "493:\tlearn: 0.0464871\ttotal: 3.5s\tremaining: 3.59s\n",
      "494:\tlearn: 0.0464794\ttotal: 3.51s\tremaining: 3.58s\n",
      "495:\tlearn: 0.0464680\ttotal: 3.52s\tremaining: 3.58s\n",
      "496:\tlearn: 0.0464624\ttotal: 3.53s\tremaining: 3.57s\n",
      "497:\tlearn: 0.0464236\ttotal: 3.54s\tremaining: 3.57s\n",
      "498:\tlearn: 0.0464167\ttotal: 3.55s\tremaining: 3.57s\n",
      "499:\tlearn: 0.0463992\ttotal: 3.56s\tremaining: 3.56s\n",
      "500:\tlearn: 0.0463867\ttotal: 3.57s\tremaining: 3.55s\n",
      "501:\tlearn: 0.0463844\ttotal: 3.57s\tremaining: 3.55s\n",
      "502:\tlearn: 0.0463812\ttotal: 3.58s\tremaining: 3.54s\n",
      "503:\tlearn: 0.0463723\ttotal: 3.59s\tremaining: 3.53s\n",
      "504:\tlearn: 0.0463676\ttotal: 3.59s\tremaining: 3.52s\n",
      "505:\tlearn: 0.0463623\ttotal: 3.6s\tremaining: 3.51s\n",
      "506:\tlearn: 0.0463565\ttotal: 3.6s\tremaining: 3.51s\n",
      "507:\tlearn: 0.0463441\ttotal: 3.61s\tremaining: 3.5s\n",
      "508:\tlearn: 0.0463335\ttotal: 3.62s\tremaining: 3.49s\n",
      "509:\tlearn: 0.0463292\ttotal: 3.63s\tremaining: 3.48s\n",
      "510:\tlearn: 0.0463243\ttotal: 3.63s\tremaining: 3.48s\n",
      "511:\tlearn: 0.0463204\ttotal: 3.64s\tremaining: 3.47s\n",
      "512:\tlearn: 0.0462983\ttotal: 3.65s\tremaining: 3.46s\n",
      "513:\tlearn: 0.0462869\ttotal: 3.65s\tremaining: 3.46s\n",
      "514:\tlearn: 0.0462775\ttotal: 3.66s\tremaining: 3.45s\n",
      "515:\tlearn: 0.0462746\ttotal: 3.67s\tremaining: 3.44s\n",
      "516:\tlearn: 0.0462575\ttotal: 3.67s\tremaining: 3.43s\n",
      "517:\tlearn: 0.0462519\ttotal: 3.68s\tremaining: 3.43s\n",
      "518:\tlearn: 0.0462478\ttotal: 3.69s\tremaining: 3.42s\n",
      "519:\tlearn: 0.0462384\ttotal: 3.69s\tremaining: 3.41s\n",
      "520:\tlearn: 0.0462164\ttotal: 3.7s\tremaining: 3.4s\n",
      "521:\tlearn: 0.0462130\ttotal: 3.71s\tremaining: 3.4s\n",
      "522:\tlearn: 0.0462052\ttotal: 3.71s\tremaining: 3.39s\n",
      "523:\tlearn: 0.0462023\ttotal: 3.72s\tremaining: 3.38s\n",
      "524:\tlearn: 0.0461937\ttotal: 3.73s\tremaining: 3.38s\n",
      "525:\tlearn: 0.0461903\ttotal: 3.74s\tremaining: 3.37s\n",
      "526:\tlearn: 0.0461898\ttotal: 3.75s\tremaining: 3.36s\n",
      "527:\tlearn: 0.0461816\ttotal: 3.75s\tremaining: 3.36s\n",
      "528:\tlearn: 0.0461563\ttotal: 3.77s\tremaining: 3.36s\n",
      "529:\tlearn: 0.0461528\ttotal: 3.78s\tremaining: 3.35s\n",
      "530:\tlearn: 0.0461198\ttotal: 3.79s\tremaining: 3.34s\n",
      "531:\tlearn: 0.0461123\ttotal: 3.79s\tremaining: 3.34s\n",
      "532:\tlearn: 0.0460961\ttotal: 3.8s\tremaining: 3.33s\n",
      "533:\tlearn: 0.0460890\ttotal: 3.81s\tremaining: 3.33s\n",
      "534:\tlearn: 0.0460734\ttotal: 3.82s\tremaining: 3.32s\n",
      "535:\tlearn: 0.0460704\ttotal: 3.83s\tremaining: 3.31s\n",
      "536:\tlearn: 0.0460606\ttotal: 3.84s\tremaining: 3.31s\n",
      "537:\tlearn: 0.0460499\ttotal: 3.85s\tremaining: 3.3s\n",
      "538:\tlearn: 0.0460395\ttotal: 3.85s\tremaining: 3.29s\n",
      "539:\tlearn: 0.0460351\ttotal: 3.86s\tremaining: 3.29s\n",
      "540:\tlearn: 0.0460309\ttotal: 3.87s\tremaining: 3.29s\n",
      "541:\tlearn: 0.0460270\ttotal: 3.88s\tremaining: 3.28s\n",
      "542:\tlearn: 0.0460268\ttotal: 3.89s\tremaining: 3.27s\n",
      "543:\tlearn: 0.0460230\ttotal: 3.89s\tremaining: 3.26s\n",
      "544:\tlearn: 0.0460084\ttotal: 3.9s\tremaining: 3.26s\n",
      "545:\tlearn: 0.0459981\ttotal: 3.91s\tremaining: 3.25s\n",
      "546:\tlearn: 0.0459979\ttotal: 3.92s\tremaining: 3.24s\n",
      "547:\tlearn: 0.0459799\ttotal: 3.92s\tremaining: 3.24s\n",
      "548:\tlearn: 0.0459764\ttotal: 3.94s\tremaining: 3.23s\n",
      "549:\tlearn: 0.0459726\ttotal: 3.94s\tremaining: 3.23s\n",
      "550:\tlearn: 0.0459386\ttotal: 3.95s\tremaining: 3.22s\n",
      "551:\tlearn: 0.0459363\ttotal: 3.96s\tremaining: 3.21s\n",
      "552:\tlearn: 0.0459026\ttotal: 3.97s\tremaining: 3.21s\n",
      "553:\tlearn: 0.0458988\ttotal: 3.98s\tremaining: 3.21s\n",
      "554:\tlearn: 0.0458972\ttotal: 3.99s\tremaining: 3.2s\n",
      "555:\tlearn: 0.0458938\ttotal: 4s\tremaining: 3.19s\n",
      "556:\tlearn: 0.0458841\ttotal: 4.01s\tremaining: 3.19s\n",
      "557:\tlearn: 0.0458808\ttotal: 4.02s\tremaining: 3.18s\n",
      "558:\tlearn: 0.0458784\ttotal: 4.03s\tremaining: 3.18s\n",
      "559:\tlearn: 0.0458759\ttotal: 4.04s\tremaining: 3.17s\n",
      "560:\tlearn: 0.0458689\ttotal: 4.05s\tremaining: 3.17s\n",
      "561:\tlearn: 0.0458598\ttotal: 4.05s\tremaining: 3.16s\n",
      "562:\tlearn: 0.0458452\ttotal: 4.06s\tremaining: 3.15s\n",
      "563:\tlearn: 0.0458421\ttotal: 4.07s\tremaining: 3.15s\n",
      "564:\tlearn: 0.0458328\ttotal: 4.08s\tremaining: 3.14s\n",
      "565:\tlearn: 0.0458254\ttotal: 4.09s\tremaining: 3.13s\n",
      "566:\tlearn: 0.0458074\ttotal: 4.09s\tremaining: 3.13s\n",
      "567:\tlearn: 0.0458056\ttotal: 4.1s\tremaining: 3.12s\n",
      "568:\tlearn: 0.0458030\ttotal: 4.11s\tremaining: 3.11s\n",
      "569:\tlearn: 0.0458015\ttotal: 4.12s\tremaining: 3.11s\n",
      "570:\tlearn: 0.0457783\ttotal: 4.13s\tremaining: 3.1s\n",
      "571:\tlearn: 0.0457706\ttotal: 4.14s\tremaining: 3.1s\n",
      "572:\tlearn: 0.0457697\ttotal: 4.15s\tremaining: 3.09s\n",
      "573:\tlearn: 0.0457483\ttotal: 4.16s\tremaining: 3.08s\n",
      "574:\tlearn: 0.0457479\ttotal: 4.16s\tremaining: 3.08s\n",
      "575:\tlearn: 0.0457416\ttotal: 4.17s\tremaining: 3.07s\n",
      "576:\tlearn: 0.0457409\ttotal: 4.18s\tremaining: 3.06s\n",
      "577:\tlearn: 0.0457377\ttotal: 4.18s\tremaining: 3.06s\n",
      "578:\tlearn: 0.0457313\ttotal: 4.19s\tremaining: 3.05s\n",
      "579:\tlearn: 0.0456993\ttotal: 4.2s\tremaining: 3.04s\n",
      "580:\tlearn: 0.0456496\ttotal: 4.21s\tremaining: 3.04s\n",
      "581:\tlearn: 0.0456478\ttotal: 4.22s\tremaining: 3.03s\n",
      "582:\tlearn: 0.0456452\ttotal: 4.23s\tremaining: 3.02s\n",
      "583:\tlearn: 0.0456233\ttotal: 4.24s\tremaining: 3.02s\n",
      "584:\tlearn: 0.0456052\ttotal: 4.25s\tremaining: 3.01s\n",
      "585:\tlearn: 0.0456008\ttotal: 4.25s\tremaining: 3.01s\n",
      "586:\tlearn: 0.0455975\ttotal: 4.26s\tremaining: 3s\n",
      "587:\tlearn: 0.0455865\ttotal: 4.27s\tremaining: 2.99s\n",
      "588:\tlearn: 0.0455639\ttotal: 4.28s\tremaining: 2.99s\n",
      "589:\tlearn: 0.0455584\ttotal: 4.29s\tremaining: 2.98s\n",
      "590:\tlearn: 0.0455584\ttotal: 4.3s\tremaining: 2.97s\n",
      "591:\tlearn: 0.0455501\ttotal: 4.3s\tremaining: 2.97s\n",
      "592:\tlearn: 0.0455439\ttotal: 4.31s\tremaining: 2.96s\n",
      "593:\tlearn: 0.0455340\ttotal: 4.32s\tremaining: 2.95s\n",
      "594:\tlearn: 0.0455304\ttotal: 4.33s\tremaining: 2.94s\n",
      "595:\tlearn: 0.0455276\ttotal: 4.33s\tremaining: 2.94s\n",
      "596:\tlearn: 0.0455263\ttotal: 4.34s\tremaining: 2.93s\n",
      "597:\tlearn: 0.0455164\ttotal: 4.35s\tremaining: 2.92s\n",
      "598:\tlearn: 0.0455136\ttotal: 4.36s\tremaining: 2.92s\n",
      "599:\tlearn: 0.0455114\ttotal: 4.37s\tremaining: 2.91s\n",
      "600:\tlearn: 0.0455031\ttotal: 4.38s\tremaining: 2.9s\n",
      "601:\tlearn: 0.0455009\ttotal: 4.38s\tremaining: 2.9s\n",
      "602:\tlearn: 0.0454909\ttotal: 4.39s\tremaining: 2.89s\n",
      "603:\tlearn: 0.0454821\ttotal: 4.4s\tremaining: 2.88s\n",
      "604:\tlearn: 0.0454782\ttotal: 4.41s\tremaining: 2.88s\n",
      "605:\tlearn: 0.0454679\ttotal: 4.42s\tremaining: 2.87s\n",
      "606:\tlearn: 0.0454512\ttotal: 4.43s\tremaining: 2.87s\n",
      "607:\tlearn: 0.0454449\ttotal: 4.43s\tremaining: 2.86s\n",
      "608:\tlearn: 0.0454358\ttotal: 4.45s\tremaining: 2.85s\n",
      "609:\tlearn: 0.0454204\ttotal: 4.45s\tremaining: 2.85s\n",
      "610:\tlearn: 0.0454156\ttotal: 4.46s\tremaining: 2.84s\n",
      "611:\tlearn: 0.0453858\ttotal: 4.47s\tremaining: 2.83s\n",
      "612:\tlearn: 0.0453848\ttotal: 4.48s\tremaining: 2.83s\n",
      "613:\tlearn: 0.0453795\ttotal: 4.49s\tremaining: 2.82s\n",
      "614:\tlearn: 0.0453732\ttotal: 4.5s\tremaining: 2.82s\n",
      "615:\tlearn: 0.0453642\ttotal: 4.51s\tremaining: 2.81s\n",
      "616:\tlearn: 0.0453466\ttotal: 4.52s\tremaining: 2.8s\n",
      "617:\tlearn: 0.0453256\ttotal: 4.53s\tremaining: 2.8s\n",
      "618:\tlearn: 0.0453144\ttotal: 4.53s\tremaining: 2.79s\n",
      "619:\tlearn: 0.0452938\ttotal: 4.55s\tremaining: 2.79s\n",
      "620:\tlearn: 0.0452790\ttotal: 4.56s\tremaining: 2.78s\n",
      "621:\tlearn: 0.0452749\ttotal: 4.57s\tremaining: 2.77s\n",
      "622:\tlearn: 0.0452621\ttotal: 4.58s\tremaining: 2.77s\n",
      "623:\tlearn: 0.0452584\ttotal: 4.58s\tremaining: 2.76s\n",
      "624:\tlearn: 0.0452473\ttotal: 4.59s\tremaining: 2.75s\n",
      "625:\tlearn: 0.0452393\ttotal: 4.6s\tremaining: 2.75s\n",
      "626:\tlearn: 0.0452197\ttotal: 4.61s\tremaining: 2.74s\n",
      "627:\tlearn: 0.0452080\ttotal: 4.62s\tremaining: 2.74s\n",
      "628:\tlearn: 0.0451991\ttotal: 4.63s\tremaining: 2.73s\n",
      "629:\tlearn: 0.0451983\ttotal: 4.63s\tremaining: 2.72s\n",
      "630:\tlearn: 0.0451930\ttotal: 4.64s\tremaining: 2.71s\n",
      "631:\tlearn: 0.0451755\ttotal: 4.65s\tremaining: 2.71s\n",
      "632:\tlearn: 0.0451587\ttotal: 4.66s\tremaining: 2.7s\n",
      "633:\tlearn: 0.0451451\ttotal: 4.67s\tremaining: 2.69s\n",
      "634:\tlearn: 0.0451291\ttotal: 4.67s\tremaining: 2.69s\n",
      "635:\tlearn: 0.0451271\ttotal: 4.68s\tremaining: 2.68s\n",
      "636:\tlearn: 0.0451222\ttotal: 4.69s\tremaining: 2.67s\n",
      "637:\tlearn: 0.0451085\ttotal: 4.7s\tremaining: 2.67s\n",
      "638:\tlearn: 0.0450914\ttotal: 4.7s\tremaining: 2.66s\n",
      "639:\tlearn: 0.0450850\ttotal: 4.71s\tremaining: 2.65s\n",
      "640:\tlearn: 0.0450804\ttotal: 4.72s\tremaining: 2.64s\n",
      "641:\tlearn: 0.0450619\ttotal: 4.73s\tremaining: 2.64s\n",
      "642:\tlearn: 0.0450609\ttotal: 4.73s\tremaining: 2.63s\n",
      "643:\tlearn: 0.0450588\ttotal: 4.74s\tremaining: 2.62s\n",
      "644:\tlearn: 0.0450567\ttotal: 4.75s\tremaining: 2.61s\n",
      "645:\tlearn: 0.0450556\ttotal: 4.76s\tremaining: 2.61s\n",
      "646:\tlearn: 0.0450532\ttotal: 4.77s\tremaining: 2.6s\n",
      "647:\tlearn: 0.0450345\ttotal: 4.77s\tremaining: 2.59s\n",
      "648:\tlearn: 0.0450317\ttotal: 4.78s\tremaining: 2.59s\n",
      "649:\tlearn: 0.0450287\ttotal: 4.79s\tremaining: 2.58s\n",
      "650:\tlearn: 0.0450095\ttotal: 4.8s\tremaining: 2.57s\n",
      "651:\tlearn: 0.0450015\ttotal: 4.81s\tremaining: 2.57s\n",
      "652:\tlearn: 0.0449666\ttotal: 4.82s\tremaining: 2.56s\n",
      "653:\tlearn: 0.0449490\ttotal: 4.82s\tremaining: 2.55s\n",
      "654:\tlearn: 0.0449450\ttotal: 4.83s\tremaining: 2.54s\n",
      "655:\tlearn: 0.0449133\ttotal: 4.84s\tremaining: 2.54s\n",
      "656:\tlearn: 0.0448850\ttotal: 4.84s\tremaining: 2.53s\n",
      "657:\tlearn: 0.0448789\ttotal: 4.85s\tremaining: 2.52s\n",
      "658:\tlearn: 0.0448494\ttotal: 4.86s\tremaining: 2.51s\n",
      "659:\tlearn: 0.0448469\ttotal: 4.87s\tremaining: 2.51s\n",
      "660:\tlearn: 0.0448426\ttotal: 4.88s\tremaining: 2.5s\n",
      "661:\tlearn: 0.0448394\ttotal: 4.88s\tremaining: 2.49s\n",
      "662:\tlearn: 0.0448332\ttotal: 4.89s\tremaining: 2.48s\n",
      "663:\tlearn: 0.0448287\ttotal: 4.9s\tremaining: 2.48s\n",
      "664:\tlearn: 0.0448166\ttotal: 4.91s\tremaining: 2.47s\n",
      "665:\tlearn: 0.0448149\ttotal: 4.91s\tremaining: 2.46s\n",
      "666:\tlearn: 0.0447927\ttotal: 4.92s\tremaining: 2.46s\n",
      "667:\tlearn: 0.0447914\ttotal: 4.92s\tremaining: 2.45s\n",
      "668:\tlearn: 0.0447883\ttotal: 4.93s\tremaining: 2.44s\n",
      "669:\tlearn: 0.0447869\ttotal: 4.94s\tremaining: 2.43s\n",
      "670:\tlearn: 0.0447863\ttotal: 4.94s\tremaining: 2.42s\n",
      "671:\tlearn: 0.0447782\ttotal: 4.95s\tremaining: 2.42s\n",
      "672:\tlearn: 0.0447627\ttotal: 4.96s\tremaining: 2.41s\n",
      "673:\tlearn: 0.0447608\ttotal: 4.97s\tremaining: 2.4s\n",
      "674:\tlearn: 0.0447608\ttotal: 4.97s\tremaining: 2.39s\n",
      "675:\tlearn: 0.0447535\ttotal: 4.98s\tremaining: 2.39s\n",
      "676:\tlearn: 0.0447501\ttotal: 4.99s\tremaining: 2.38s\n",
      "677:\tlearn: 0.0447361\ttotal: 5s\tremaining: 2.37s\n",
      "678:\tlearn: 0.0447316\ttotal: 5s\tremaining: 2.37s\n",
      "679:\tlearn: 0.0447059\ttotal: 5.01s\tremaining: 2.36s\n",
      "680:\tlearn: 0.0446963\ttotal: 5.02s\tremaining: 2.35s\n",
      "681:\tlearn: 0.0446924\ttotal: 5.03s\tremaining: 2.34s\n",
      "682:\tlearn: 0.0446915\ttotal: 5.04s\tremaining: 2.34s\n",
      "683:\tlearn: 0.0446872\ttotal: 5.04s\tremaining: 2.33s\n",
      "684:\tlearn: 0.0446785\ttotal: 5.05s\tremaining: 2.32s\n",
      "685:\tlearn: 0.0446661\ttotal: 5.06s\tremaining: 2.32s\n",
      "686:\tlearn: 0.0446621\ttotal: 5.07s\tremaining: 2.31s\n",
      "687:\tlearn: 0.0446553\ttotal: 5.08s\tremaining: 2.3s\n",
      "688:\tlearn: 0.0446510\ttotal: 5.08s\tremaining: 2.29s\n",
      "689:\tlearn: 0.0446490\ttotal: 5.09s\tremaining: 2.29s\n",
      "690:\tlearn: 0.0446395\ttotal: 5.1s\tremaining: 2.28s\n",
      "691:\tlearn: 0.0446331\ttotal: 5.11s\tremaining: 2.27s\n",
      "692:\tlearn: 0.0446296\ttotal: 5.12s\tremaining: 2.27s\n",
      "693:\tlearn: 0.0446238\ttotal: 5.12s\tremaining: 2.26s\n",
      "694:\tlearn: 0.0446129\ttotal: 5.13s\tremaining: 2.25s\n",
      "695:\tlearn: 0.0446055\ttotal: 5.14s\tremaining: 2.25s\n",
      "696:\tlearn: 0.0446046\ttotal: 5.15s\tremaining: 2.24s\n",
      "697:\tlearn: 0.0446001\ttotal: 5.16s\tremaining: 2.23s\n",
      "698:\tlearn: 0.0445946\ttotal: 5.17s\tremaining: 2.23s\n",
      "699:\tlearn: 0.0445852\ttotal: 5.18s\tremaining: 2.22s\n",
      "700:\tlearn: 0.0445826\ttotal: 5.19s\tremaining: 2.21s\n",
      "701:\tlearn: 0.0445631\ttotal: 5.2s\tremaining: 2.21s\n",
      "702:\tlearn: 0.0445623\ttotal: 5.21s\tremaining: 2.2s\n",
      "703:\tlearn: 0.0445575\ttotal: 5.22s\tremaining: 2.19s\n",
      "704:\tlearn: 0.0445550\ttotal: 5.23s\tremaining: 2.19s\n",
      "705:\tlearn: 0.0445436\ttotal: 5.24s\tremaining: 2.18s\n",
      "706:\tlearn: 0.0445384\ttotal: 5.24s\tremaining: 2.17s\n",
      "707:\tlearn: 0.0445260\ttotal: 5.25s\tremaining: 2.17s\n",
      "708:\tlearn: 0.0445204\ttotal: 5.26s\tremaining: 2.16s\n",
      "709:\tlearn: 0.0445194\ttotal: 5.27s\tremaining: 2.15s\n",
      "710:\tlearn: 0.0445009\ttotal: 5.28s\tremaining: 2.14s\n",
      "711:\tlearn: 0.0444876\ttotal: 5.29s\tremaining: 2.14s\n",
      "712:\tlearn: 0.0444802\ttotal: 5.29s\tremaining: 2.13s\n",
      "713:\tlearn: 0.0444734\ttotal: 5.3s\tremaining: 2.12s\n",
      "714:\tlearn: 0.0444706\ttotal: 5.31s\tremaining: 2.12s\n",
      "715:\tlearn: 0.0444465\ttotal: 5.32s\tremaining: 2.11s\n",
      "716:\tlearn: 0.0444412\ttotal: 5.33s\tremaining: 2.1s\n",
      "717:\tlearn: 0.0444295\ttotal: 5.33s\tremaining: 2.1s\n",
      "718:\tlearn: 0.0444212\ttotal: 5.34s\tremaining: 2.09s\n",
      "719:\tlearn: 0.0444174\ttotal: 5.35s\tremaining: 2.08s\n",
      "720:\tlearn: 0.0444030\ttotal: 5.36s\tremaining: 2.07s\n",
      "721:\tlearn: 0.0444006\ttotal: 5.37s\tremaining: 2.07s\n",
      "722:\tlearn: 0.0443919\ttotal: 5.38s\tremaining: 2.06s\n",
      "723:\tlearn: 0.0443839\ttotal: 5.38s\tremaining: 2.05s\n",
      "724:\tlearn: 0.0443830\ttotal: 5.39s\tremaining: 2.04s\n",
      "725:\tlearn: 0.0443712\ttotal: 5.4s\tremaining: 2.04s\n",
      "726:\tlearn: 0.0443579\ttotal: 5.42s\tremaining: 2.03s\n",
      "727:\tlearn: 0.0443409\ttotal: 5.42s\tremaining: 2.03s\n",
      "728:\tlearn: 0.0443342\ttotal: 5.43s\tremaining: 2.02s\n",
      "729:\tlearn: 0.0443278\ttotal: 5.44s\tremaining: 2.01s\n",
      "730:\tlearn: 0.0443264\ttotal: 5.45s\tremaining: 2s\n",
      "731:\tlearn: 0.0443263\ttotal: 5.46s\tremaining: 2s\n",
      "732:\tlearn: 0.0443217\ttotal: 5.46s\tremaining: 1.99s\n",
      "733:\tlearn: 0.0443168\ttotal: 5.47s\tremaining: 1.98s\n",
      "734:\tlearn: 0.0443009\ttotal: 5.48s\tremaining: 1.98s\n",
      "735:\tlearn: 0.0442979\ttotal: 5.49s\tremaining: 1.97s\n",
      "736:\tlearn: 0.0442865\ttotal: 5.5s\tremaining: 1.96s\n",
      "737:\tlearn: 0.0442659\ttotal: 5.5s\tremaining: 1.95s\n",
      "738:\tlearn: 0.0442636\ttotal: 5.51s\tremaining: 1.95s\n",
      "739:\tlearn: 0.0442231\ttotal: 5.52s\tremaining: 1.94s\n",
      "740:\tlearn: 0.0442070\ttotal: 5.53s\tremaining: 1.93s\n",
      "741:\tlearn: 0.0442056\ttotal: 5.54s\tremaining: 1.93s\n",
      "742:\tlearn: 0.0441934\ttotal: 5.55s\tremaining: 1.92s\n",
      "743:\tlearn: 0.0441876\ttotal: 5.56s\tremaining: 1.91s\n",
      "744:\tlearn: 0.0441778\ttotal: 5.57s\tremaining: 1.91s\n",
      "745:\tlearn: 0.0441617\ttotal: 5.57s\tremaining: 1.9s\n",
      "746:\tlearn: 0.0441577\ttotal: 5.58s\tremaining: 1.89s\n",
      "747:\tlearn: 0.0441517\ttotal: 5.59s\tremaining: 1.88s\n",
      "748:\tlearn: 0.0441476\ttotal: 5.59s\tremaining: 1.87s\n",
      "749:\tlearn: 0.0441458\ttotal: 5.6s\tremaining: 1.87s\n",
      "750:\tlearn: 0.0441414\ttotal: 5.61s\tremaining: 1.86s\n",
      "751:\tlearn: 0.0441348\ttotal: 5.62s\tremaining: 1.85s\n",
      "752:\tlearn: 0.0441333\ttotal: 5.62s\tremaining: 1.84s\n",
      "753:\tlearn: 0.0441285\ttotal: 5.63s\tremaining: 1.84s\n",
      "754:\tlearn: 0.0441190\ttotal: 5.64s\tremaining: 1.83s\n",
      "755:\tlearn: 0.0441160\ttotal: 5.65s\tremaining: 1.82s\n",
      "756:\tlearn: 0.0441114\ttotal: 5.66s\tremaining: 1.81s\n",
      "757:\tlearn: 0.0441021\ttotal: 5.67s\tremaining: 1.81s\n",
      "758:\tlearn: 0.0440986\ttotal: 5.67s\tremaining: 1.8s\n",
      "759:\tlearn: 0.0440938\ttotal: 5.68s\tremaining: 1.79s\n",
      "760:\tlearn: 0.0440932\ttotal: 5.69s\tremaining: 1.78s\n",
      "761:\tlearn: 0.0440927\ttotal: 5.69s\tremaining: 1.78s\n",
      "762:\tlearn: 0.0440774\ttotal: 5.7s\tremaining: 1.77s\n",
      "763:\tlearn: 0.0440633\ttotal: 5.71s\tremaining: 1.76s\n",
      "764:\tlearn: 0.0440591\ttotal: 5.72s\tremaining: 1.76s\n",
      "765:\tlearn: 0.0440492\ttotal: 5.73s\tremaining: 1.75s\n",
      "766:\tlearn: 0.0440453\ttotal: 5.73s\tremaining: 1.74s\n",
      "767:\tlearn: 0.0440394\ttotal: 5.74s\tremaining: 1.73s\n",
      "768:\tlearn: 0.0440358\ttotal: 5.75s\tremaining: 1.73s\n",
      "769:\tlearn: 0.0440350\ttotal: 5.75s\tremaining: 1.72s\n",
      "770:\tlearn: 0.0440236\ttotal: 5.77s\tremaining: 1.71s\n",
      "771:\tlearn: 0.0439994\ttotal: 5.78s\tremaining: 1.71s\n",
      "772:\tlearn: 0.0439975\ttotal: 5.79s\tremaining: 1.7s\n",
      "773:\tlearn: 0.0439873\ttotal: 5.79s\tremaining: 1.69s\n",
      "774:\tlearn: 0.0439845\ttotal: 5.8s\tremaining: 1.69s\n",
      "775:\tlearn: 0.0439752\ttotal: 5.81s\tremaining: 1.68s\n",
      "776:\tlearn: 0.0439583\ttotal: 5.82s\tremaining: 1.67s\n",
      "777:\tlearn: 0.0439428\ttotal: 5.82s\tremaining: 1.66s\n",
      "778:\tlearn: 0.0439158\ttotal: 5.83s\tremaining: 1.65s\n",
      "779:\tlearn: 0.0439023\ttotal: 5.84s\tremaining: 1.65s\n",
      "780:\tlearn: 0.0438794\ttotal: 5.85s\tremaining: 1.64s\n",
      "781:\tlearn: 0.0438628\ttotal: 5.86s\tremaining: 1.63s\n",
      "782:\tlearn: 0.0438568\ttotal: 5.87s\tremaining: 1.63s\n",
      "783:\tlearn: 0.0438425\ttotal: 5.87s\tremaining: 1.62s\n",
      "784:\tlearn: 0.0438315\ttotal: 5.88s\tremaining: 1.61s\n",
      "785:\tlearn: 0.0438138\ttotal: 5.89s\tremaining: 1.6s\n",
      "786:\tlearn: 0.0438060\ttotal: 5.9s\tremaining: 1.6s\n",
      "787:\tlearn: 0.0438043\ttotal: 5.91s\tremaining: 1.59s\n",
      "788:\tlearn: 0.0437882\ttotal: 5.91s\tremaining: 1.58s\n",
      "789:\tlearn: 0.0437745\ttotal: 5.92s\tremaining: 1.57s\n",
      "790:\tlearn: 0.0437612\ttotal: 5.93s\tremaining: 1.57s\n",
      "791:\tlearn: 0.0437371\ttotal: 5.94s\tremaining: 1.56s\n",
      "792:\tlearn: 0.0437362\ttotal: 5.95s\tremaining: 1.55s\n",
      "793:\tlearn: 0.0437234\ttotal: 5.96s\tremaining: 1.55s\n",
      "794:\tlearn: 0.0437169\ttotal: 5.97s\tremaining: 1.54s\n",
      "795:\tlearn: 0.0437081\ttotal: 5.98s\tremaining: 1.53s\n",
      "796:\tlearn: 0.0437007\ttotal: 5.99s\tremaining: 1.52s\n",
      "797:\tlearn: 0.0436940\ttotal: 6s\tremaining: 1.52s\n",
      "798:\tlearn: 0.0436936\ttotal: 6s\tremaining: 1.51s\n",
      "799:\tlearn: 0.0436688\ttotal: 6.01s\tremaining: 1.5s\n",
      "800:\tlearn: 0.0436634\ttotal: 6.02s\tremaining: 1.5s\n",
      "801:\tlearn: 0.0436522\ttotal: 6.03s\tremaining: 1.49s\n",
      "802:\tlearn: 0.0436378\ttotal: 6.04s\tremaining: 1.48s\n",
      "803:\tlearn: 0.0436259\ttotal: 6.04s\tremaining: 1.47s\n",
      "804:\tlearn: 0.0436222\ttotal: 6.05s\tremaining: 1.47s\n",
      "805:\tlearn: 0.0436212\ttotal: 6.06s\tremaining: 1.46s\n",
      "806:\tlearn: 0.0436169\ttotal: 6.07s\tremaining: 1.45s\n",
      "807:\tlearn: 0.0435986\ttotal: 6.08s\tremaining: 1.44s\n",
      "808:\tlearn: 0.0435794\ttotal: 6.09s\tremaining: 1.44s\n",
      "809:\tlearn: 0.0435599\ttotal: 6.1s\tremaining: 1.43s\n",
      "810:\tlearn: 0.0435528\ttotal: 6.11s\tremaining: 1.42s\n",
      "811:\tlearn: 0.0435404\ttotal: 6.12s\tremaining: 1.42s\n",
      "812:\tlearn: 0.0435372\ttotal: 6.13s\tremaining: 1.41s\n",
      "813:\tlearn: 0.0435338\ttotal: 6.13s\tremaining: 1.4s\n",
      "814:\tlearn: 0.0435267\ttotal: 6.14s\tremaining: 1.39s\n",
      "815:\tlearn: 0.0435014\ttotal: 6.15s\tremaining: 1.39s\n",
      "816:\tlearn: 0.0434788\ttotal: 6.16s\tremaining: 1.38s\n",
      "817:\tlearn: 0.0434668\ttotal: 6.16s\tremaining: 1.37s\n",
      "818:\tlearn: 0.0434639\ttotal: 6.17s\tremaining: 1.36s\n",
      "819:\tlearn: 0.0434632\ttotal: 6.18s\tremaining: 1.36s\n",
      "820:\tlearn: 0.0434613\ttotal: 6.19s\tremaining: 1.35s\n",
      "821:\tlearn: 0.0434602\ttotal: 6.2s\tremaining: 1.34s\n",
      "822:\tlearn: 0.0434526\ttotal: 6.21s\tremaining: 1.33s\n",
      "823:\tlearn: 0.0434477\ttotal: 6.22s\tremaining: 1.33s\n",
      "824:\tlearn: 0.0434406\ttotal: 6.23s\tremaining: 1.32s\n",
      "825:\tlearn: 0.0434344\ttotal: 6.24s\tremaining: 1.31s\n",
      "826:\tlearn: 0.0434235\ttotal: 6.24s\tremaining: 1.31s\n",
      "827:\tlearn: 0.0434205\ttotal: 6.25s\tremaining: 1.3s\n",
      "828:\tlearn: 0.0434119\ttotal: 6.26s\tremaining: 1.29s\n",
      "829:\tlearn: 0.0434008\ttotal: 6.27s\tremaining: 1.28s\n",
      "830:\tlearn: 0.0433962\ttotal: 6.28s\tremaining: 1.28s\n",
      "831:\tlearn: 0.0433882\ttotal: 6.29s\tremaining: 1.27s\n",
      "832:\tlearn: 0.0433849\ttotal: 6.3s\tremaining: 1.26s\n",
      "833:\tlearn: 0.0433688\ttotal: 6.31s\tremaining: 1.26s\n",
      "834:\tlearn: 0.0433684\ttotal: 6.32s\tremaining: 1.25s\n",
      "835:\tlearn: 0.0433452\ttotal: 6.33s\tremaining: 1.24s\n",
      "836:\tlearn: 0.0433367\ttotal: 6.34s\tremaining: 1.24s\n",
      "837:\tlearn: 0.0433184\ttotal: 6.35s\tremaining: 1.23s\n",
      "838:\tlearn: 0.0433082\ttotal: 6.36s\tremaining: 1.22s\n",
      "839:\tlearn: 0.0432995\ttotal: 6.37s\tremaining: 1.21s\n",
      "840:\tlearn: 0.0432887\ttotal: 6.38s\tremaining: 1.21s\n",
      "841:\tlearn: 0.0432726\ttotal: 6.39s\tremaining: 1.2s\n",
      "842:\tlearn: 0.0432702\ttotal: 6.4s\tremaining: 1.19s\n",
      "843:\tlearn: 0.0432558\ttotal: 6.41s\tremaining: 1.19s\n",
      "844:\tlearn: 0.0432533\ttotal: 6.42s\tremaining: 1.18s\n",
      "845:\tlearn: 0.0432255\ttotal: 6.43s\tremaining: 1.17s\n",
      "846:\tlearn: 0.0432247\ttotal: 6.44s\tremaining: 1.16s\n",
      "847:\tlearn: 0.0432236\ttotal: 6.45s\tremaining: 1.16s\n",
      "848:\tlearn: 0.0432179\ttotal: 6.46s\tremaining: 1.15s\n",
      "849:\tlearn: 0.0432110\ttotal: 6.46s\tremaining: 1.14s\n",
      "850:\tlearn: 0.0432083\ttotal: 6.47s\tremaining: 1.13s\n",
      "851:\tlearn: 0.0431891\ttotal: 6.48s\tremaining: 1.13s\n",
      "852:\tlearn: 0.0431745\ttotal: 6.49s\tremaining: 1.12s\n",
      "853:\tlearn: 0.0431693\ttotal: 6.5s\tremaining: 1.11s\n",
      "854:\tlearn: 0.0431642\ttotal: 6.51s\tremaining: 1.1s\n",
      "855:\tlearn: 0.0431536\ttotal: 6.52s\tremaining: 1.1s\n",
      "856:\tlearn: 0.0431515\ttotal: 6.52s\tremaining: 1.09s\n",
      "857:\tlearn: 0.0431351\ttotal: 6.53s\tremaining: 1.08s\n",
      "858:\tlearn: 0.0431231\ttotal: 6.54s\tremaining: 1.07s\n",
      "859:\tlearn: 0.0431110\ttotal: 6.55s\tremaining: 1.06s\n",
      "860:\tlearn: 0.0431030\ttotal: 6.56s\tremaining: 1.06s\n",
      "861:\tlearn: 0.0430978\ttotal: 6.57s\tremaining: 1.05s\n",
      "862:\tlearn: 0.0430826\ttotal: 6.57s\tremaining: 1.04s\n",
      "863:\tlearn: 0.0430734\ttotal: 6.58s\tremaining: 1.03s\n",
      "864:\tlearn: 0.0430576\ttotal: 6.59s\tremaining: 1.03s\n",
      "865:\tlearn: 0.0430434\ttotal: 6.59s\tremaining: 1.02s\n",
      "866:\tlearn: 0.0430432\ttotal: 6.6s\tremaining: 1.01s\n",
      "867:\tlearn: 0.0430300\ttotal: 6.61s\tremaining: 1s\n",
      "868:\tlearn: 0.0430165\ttotal: 6.62s\tremaining: 997ms\n",
      "869:\tlearn: 0.0430124\ttotal: 6.63s\tremaining: 990ms\n",
      "870:\tlearn: 0.0430052\ttotal: 6.63s\tremaining: 983ms\n",
      "871:\tlearn: 0.0429968\ttotal: 6.64s\tremaining: 975ms\n",
      "872:\tlearn: 0.0429806\ttotal: 6.65s\tremaining: 968ms\n",
      "873:\tlearn: 0.0429775\ttotal: 6.66s\tremaining: 960ms\n",
      "874:\tlearn: 0.0429598\ttotal: 6.66s\tremaining: 952ms\n",
      "875:\tlearn: 0.0429481\ttotal: 6.67s\tremaining: 944ms\n",
      "876:\tlearn: 0.0429463\ttotal: 6.68s\tremaining: 937ms\n",
      "877:\tlearn: 0.0429407\ttotal: 6.69s\tremaining: 929ms\n",
      "878:\tlearn: 0.0429350\ttotal: 6.7s\tremaining: 922ms\n",
      "879:\tlearn: 0.0429331\ttotal: 6.71s\tremaining: 915ms\n",
      "880:\tlearn: 0.0429265\ttotal: 6.71s\tremaining: 907ms\n",
      "881:\tlearn: 0.0429205\ttotal: 6.72s\tremaining: 899ms\n",
      "882:\tlearn: 0.0429091\ttotal: 6.73s\tremaining: 891ms\n",
      "883:\tlearn: 0.0428962\ttotal: 6.74s\tremaining: 884ms\n",
      "884:\tlearn: 0.0428913\ttotal: 6.74s\tremaining: 876ms\n",
      "885:\tlearn: 0.0428901\ttotal: 6.75s\tremaining: 869ms\n",
      "886:\tlearn: 0.0428875\ttotal: 6.76s\tremaining: 862ms\n",
      "887:\tlearn: 0.0428756\ttotal: 6.77s\tremaining: 854ms\n",
      "888:\tlearn: 0.0428605\ttotal: 6.78s\tremaining: 847ms\n",
      "889:\tlearn: 0.0428604\ttotal: 6.79s\tremaining: 839ms\n",
      "890:\tlearn: 0.0428592\ttotal: 6.8s\tremaining: 832ms\n",
      "891:\tlearn: 0.0428523\ttotal: 6.8s\tremaining: 824ms\n",
      "892:\tlearn: 0.0428414\ttotal: 6.82s\tremaining: 817ms\n",
      "893:\tlearn: 0.0428382\ttotal: 6.82s\tremaining: 809ms\n",
      "894:\tlearn: 0.0428168\ttotal: 6.83s\tremaining: 802ms\n",
      "895:\tlearn: 0.0428155\ttotal: 6.84s\tremaining: 794ms\n",
      "896:\tlearn: 0.0428112\ttotal: 6.85s\tremaining: 786ms\n",
      "897:\tlearn: 0.0428102\ttotal: 6.85s\tremaining: 779ms\n",
      "898:\tlearn: 0.0428027\ttotal: 6.86s\tremaining: 771ms\n",
      "899:\tlearn: 0.0427957\ttotal: 6.87s\tremaining: 764ms\n",
      "900:\tlearn: 0.0427937\ttotal: 6.88s\tremaining: 756ms\n",
      "901:\tlearn: 0.0427876\ttotal: 6.89s\tremaining: 749ms\n",
      "902:\tlearn: 0.0427865\ttotal: 6.89s\tremaining: 741ms\n",
      "903:\tlearn: 0.0427804\ttotal: 6.9s\tremaining: 733ms\n",
      "904:\tlearn: 0.0427626\ttotal: 6.91s\tremaining: 725ms\n",
      "905:\tlearn: 0.0427614\ttotal: 6.92s\tremaining: 718ms\n",
      "906:\tlearn: 0.0427485\ttotal: 6.92s\tremaining: 710ms\n",
      "907:\tlearn: 0.0427345\ttotal: 6.93s\tremaining: 703ms\n",
      "908:\tlearn: 0.0427341\ttotal: 6.94s\tremaining: 695ms\n",
      "909:\tlearn: 0.0427330\ttotal: 6.95s\tremaining: 687ms\n",
      "910:\tlearn: 0.0427078\ttotal: 6.96s\tremaining: 680ms\n",
      "911:\tlearn: 0.0426808\ttotal: 6.97s\tremaining: 672ms\n",
      "912:\tlearn: 0.0426587\ttotal: 6.97s\tremaining: 665ms\n",
      "913:\tlearn: 0.0426521\ttotal: 6.98s\tremaining: 657ms\n",
      "914:\tlearn: 0.0426519\ttotal: 6.99s\tremaining: 649ms\n",
      "915:\tlearn: 0.0426462\ttotal: 7s\tremaining: 642ms\n",
      "916:\tlearn: 0.0426423\ttotal: 7s\tremaining: 634ms\n",
      "917:\tlearn: 0.0426359\ttotal: 7.01s\tremaining: 626ms\n",
      "918:\tlearn: 0.0426253\ttotal: 7.02s\tremaining: 619ms\n",
      "919:\tlearn: 0.0426138\ttotal: 7.03s\tremaining: 611ms\n",
      "920:\tlearn: 0.0426088\ttotal: 7.04s\tremaining: 604ms\n",
      "921:\tlearn: 0.0426076\ttotal: 7.04s\tremaining: 596ms\n",
      "922:\tlearn: 0.0425969\ttotal: 7.05s\tremaining: 588ms\n",
      "923:\tlearn: 0.0425958\ttotal: 7.06s\tremaining: 581ms\n",
      "924:\tlearn: 0.0425928\ttotal: 7.07s\tremaining: 573ms\n",
      "925:\tlearn: 0.0425925\ttotal: 7.08s\tremaining: 566ms\n",
      "926:\tlearn: 0.0425764\ttotal: 7.09s\tremaining: 558ms\n",
      "927:\tlearn: 0.0425755\ttotal: 7.09s\tremaining: 550ms\n",
      "928:\tlearn: 0.0425709\ttotal: 7.1s\tremaining: 543ms\n",
      "929:\tlearn: 0.0425583\ttotal: 7.11s\tremaining: 535ms\n",
      "930:\tlearn: 0.0425567\ttotal: 7.12s\tremaining: 528ms\n",
      "931:\tlearn: 0.0425532\ttotal: 7.13s\tremaining: 520ms\n",
      "932:\tlearn: 0.0425482\ttotal: 7.14s\tremaining: 512ms\n",
      "933:\tlearn: 0.0425429\ttotal: 7.14s\tremaining: 505ms\n",
      "934:\tlearn: 0.0425401\ttotal: 7.15s\tremaining: 497ms\n",
      "935:\tlearn: 0.0425384\ttotal: 7.16s\tremaining: 490ms\n",
      "936:\tlearn: 0.0425327\ttotal: 7.17s\tremaining: 482ms\n",
      "937:\tlearn: 0.0425264\ttotal: 7.18s\tremaining: 475ms\n",
      "938:\tlearn: 0.0425237\ttotal: 7.19s\tremaining: 467ms\n",
      "939:\tlearn: 0.0425120\ttotal: 7.2s\tremaining: 460ms\n",
      "940:\tlearn: 0.0425046\ttotal: 7.21s\tremaining: 452ms\n",
      "941:\tlearn: 0.0424913\ttotal: 7.22s\tremaining: 444ms\n",
      "942:\tlearn: 0.0424662\ttotal: 7.23s\tremaining: 437ms\n",
      "943:\tlearn: 0.0424612\ttotal: 7.24s\tremaining: 429ms\n",
      "944:\tlearn: 0.0424578\ttotal: 7.25s\tremaining: 422ms\n",
      "945:\tlearn: 0.0424530\ttotal: 7.25s\tremaining: 414ms\n",
      "946:\tlearn: 0.0424429\ttotal: 7.26s\tremaining: 406ms\n",
      "947:\tlearn: 0.0424380\ttotal: 7.27s\tremaining: 399ms\n",
      "948:\tlearn: 0.0424303\ttotal: 7.28s\tremaining: 391ms\n",
      "949:\tlearn: 0.0424242\ttotal: 7.29s\tremaining: 383ms\n",
      "950:\tlearn: 0.0424179\ttotal: 7.29s\tremaining: 376ms\n",
      "951:\tlearn: 0.0424157\ttotal: 7.3s\tremaining: 368ms\n",
      "952:\tlearn: 0.0424148\ttotal: 7.31s\tremaining: 360ms\n",
      "953:\tlearn: 0.0424104\ttotal: 7.31s\tremaining: 353ms\n",
      "954:\tlearn: 0.0424020\ttotal: 7.32s\tremaining: 345ms\n",
      "955:\tlearn: 0.0423999\ttotal: 7.33s\tremaining: 337ms\n",
      "956:\tlearn: 0.0423955\ttotal: 7.33s\tremaining: 330ms\n",
      "957:\tlearn: 0.0423886\ttotal: 7.34s\tremaining: 322ms\n",
      "958:\tlearn: 0.0423877\ttotal: 7.35s\tremaining: 314ms\n",
      "959:\tlearn: 0.0423844\ttotal: 7.35s\tremaining: 306ms\n",
      "960:\tlearn: 0.0423700\ttotal: 7.36s\tremaining: 299ms\n",
      "961:\tlearn: 0.0423476\ttotal: 7.37s\tremaining: 291ms\n",
      "962:\tlearn: 0.0423474\ttotal: 7.38s\tremaining: 284ms\n",
      "963:\tlearn: 0.0423338\ttotal: 7.39s\tremaining: 276ms\n",
      "964:\tlearn: 0.0423289\ttotal: 7.39s\tremaining: 268ms\n",
      "965:\tlearn: 0.0423195\ttotal: 7.4s\tremaining: 261ms\n",
      "966:\tlearn: 0.0423145\ttotal: 7.41s\tremaining: 253ms\n",
      "967:\tlearn: 0.0423028\ttotal: 7.42s\tremaining: 245ms\n",
      "968:\tlearn: 0.0422973\ttotal: 7.43s\tremaining: 238ms\n",
      "969:\tlearn: 0.0422902\ttotal: 7.44s\tremaining: 230ms\n",
      "970:\tlearn: 0.0422888\ttotal: 7.45s\tremaining: 222ms\n",
      "971:\tlearn: 0.0422742\ttotal: 7.45s\tremaining: 215ms\n",
      "972:\tlearn: 0.0422638\ttotal: 7.46s\tremaining: 207ms\n",
      "973:\tlearn: 0.0422610\ttotal: 7.47s\tremaining: 199ms\n",
      "974:\tlearn: 0.0422578\ttotal: 7.47s\tremaining: 192ms\n",
      "975:\tlearn: 0.0422567\ttotal: 7.48s\tremaining: 184ms\n",
      "976:\tlearn: 0.0422483\ttotal: 7.49s\tremaining: 176ms\n",
      "977:\tlearn: 0.0422283\ttotal: 7.5s\tremaining: 169ms\n",
      "978:\tlearn: 0.0422170\ttotal: 7.51s\tremaining: 161ms\n",
      "979:\tlearn: 0.0422005\ttotal: 7.52s\tremaining: 153ms\n",
      "980:\tlearn: 0.0421947\ttotal: 7.52s\tremaining: 146ms\n",
      "981:\tlearn: 0.0421891\ttotal: 7.53s\tremaining: 138ms\n",
      "982:\tlearn: 0.0421866\ttotal: 7.54s\tremaining: 130ms\n",
      "983:\tlearn: 0.0421856\ttotal: 7.55s\tremaining: 123ms\n",
      "984:\tlearn: 0.0421799\ttotal: 7.56s\tremaining: 115ms\n",
      "985:\tlearn: 0.0421756\ttotal: 7.57s\tremaining: 107ms\n",
      "986:\tlearn: 0.0421699\ttotal: 7.58s\tremaining: 99.8ms\n",
      "987:\tlearn: 0.0421571\ttotal: 7.58s\tremaining: 92.1ms\n",
      "988:\tlearn: 0.0421546\ttotal: 7.59s\tremaining: 84.5ms\n",
      "989:\tlearn: 0.0421518\ttotal: 7.6s\tremaining: 76.8ms\n",
      "990:\tlearn: 0.0421398\ttotal: 7.61s\tremaining: 69.1ms\n",
      "991:\tlearn: 0.0421338\ttotal: 7.62s\tremaining: 61.4ms\n",
      "992:\tlearn: 0.0421292\ttotal: 7.63s\tremaining: 53.8ms\n",
      "993:\tlearn: 0.0421187\ttotal: 7.63s\tremaining: 46.1ms\n",
      "994:\tlearn: 0.0421137\ttotal: 7.64s\tremaining: 38.4ms\n",
      "995:\tlearn: 0.0420977\ttotal: 7.65s\tremaining: 30.7ms\n",
      "996:\tlearn: 0.0420948\ttotal: 7.66s\tremaining: 23ms\n",
      "997:\tlearn: 0.0420885\ttotal: 7.66s\tremaining: 15.4ms\n",
      "998:\tlearn: 0.0420814\ttotal: 7.67s\tremaining: 7.68ms\n",
      "999:\tlearn: 0.0420792\ttotal: 7.68s\tremaining: 0us\n",
      "RMSE error of catboost oracle: 0.045911031163736404\n",
      "Median of target variable: 0.02755429238663843\n",
      "Mean of target variable: 0.04375963101586666\n",
      "INFO: Fitting continuum bandit for context: 1\n"
     ]
    },
    {
     "ename": "CatBoostError",
     "evalue": "Bad value for num_feature[non_default_doc_idx=0,feature_idx=8]=\"Sunday\": Cannot convert 'b'Sunday'' to float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost.get_float_feature\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._FloatOrNan\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._FloatOrNanFromString\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert 'b'Sunday'' to float",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-4a26c4f163b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_bigquery_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_ad_group_summary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-4e9ff418e64a>\u001b[0m in \u001b[0;36mtrain_bigquery_table\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;31m# train the bandit example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mdf_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mbandit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mContextualContinuumArmedBandit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbid_max_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mdill\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbandit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training data/ContextualContinuumArmedBanditCloud_JOT.dill\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-360d08155ae6>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, contexts, oracle, bid_max_value, context_ids, convergence_rate, exploration_threshold, action_col_name, kpi_name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;31m#if not type(oracle) == google.cloud.aiplatform.models.Endpoint:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0;31m#else:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;31m#    y_preds = oracle.predict(instances=[df_context.to_json()])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/catboost/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, task_type)\u001b[0m\n\u001b[1;32m   5301\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprediction_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5302\u001b[0m             \u001b[0mprediction_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_default_prediction_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5303\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5305\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstaged_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'RawFormulaVal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_period\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, parent_method_name, task_type)\u001b[0m\n\u001b[1;32m   2175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2176\u001b[0m             \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2177\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_is_single_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_predict_input_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent_method_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2178\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_prediction_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_process_predict_input_data\u001b[0;34m(self, data, parent_method_name, thread_count, label)\u001b[0m\n\u001b[1;32m   2161\u001b[0m                 \u001b[0mtext_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_text_feature_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFeaturesData\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m                 \u001b[0membedding_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_embedding_feature_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFeaturesData\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2163\u001b[0;31m                 \u001b[0mthread_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthread_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2164\u001b[0m             )\n\u001b[1;32m   2165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_single_object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, cat_features, text_features, embedding_features, column_description, pairs, delimiter, has_header, ignore_csv_quoting, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, feature_names, thread_count, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m    617\u001b[0m                     )\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_init\u001b[0;34m(self, data, label, cat_features, text_features, embedding_features, pairs, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, feature_names, thread_count)\u001b[0m\n\u001b[1;32m   1133\u001b[0m             \u001b[0mbaseline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msamples_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_baseline_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_features_order_layout_pool\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._set_features_order_data_pd_data_frame\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost.create_num_factor_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost.get_float_feature\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCatBoostError\u001b[0m: Bad value for num_feature[non_default_doc_idx=0,feature_idx=8]=\"Sunday\": Cannot convert 'b'Sunday'' to float"
     ]
    }
   ],
   "source": [
    "train_bigquery_table(df_ad_group_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a3c540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local(dataset_name):\n",
    "    \"\"\"\n",
    "    Example usage of models, oracle models etc.training them using a locally downloaded CSV file in the form of the JOT Google Ads\n",
    "    file data schema (see ./docs/data_docs/). We preprocess the raw docs in the form that it is done to put it into the BigQuery ProductionProcessedData table\n",
    "    \n",
    "    Trains a catboost oracle model and then trains a bandit using this model.\n",
    "\n",
    "    Additional fitting can be done via the fit_rounds, set to 0, or add more.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset_name : str\n",
    "        Example file of the form JOT Google Ads export\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    #dataset_name='C:\\\\Users\\\\PrasunGhosh\\\\Desktop\\\\OPERATIONAL_TESTING_DataSet-Final-Amplify_202108_20210823_QID10507419_20210824_125858_0.txt'\n",
    "    df = pd.read_csv('C:\\\\Users\\\\PrasunGhosh\\\\Desktop\\\\OPERATIONAL_TESTING_DataSet-Final-Amplify_202108_20210823_QID10507419_20210824_125858_0.txt', delimiter='\\t')\n",
    "    df.columns = ['client_id',\n",
    "                  'campaign_id',\n",
    "                  'group_id',\n",
    "                  'account_descriptive_name',\n",
    "                  'ad_network_type',\n",
    "                  'avg_position',\n",
    "                  'campaign_name',\n",
    "                  'city_criteria_id',\n",
    "                  'clicks',\n",
    "                  'cost',\n",
    "                  'impressions',\n",
    "                  'country_criteria_id',\n",
    "                  'date',\n",
    "                  'device',\n",
    "                  'external_customer_id',\n",
    "                  'metro_criteria_id',\n",
    "                  'region_criteria_id']\n",
    "\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n",
    "    df['week_day'] = df['date'].dt.day_name()\n",
    "    df['weekday_num'] = df['date'].dt.week\n",
    "    \n",
    "    id_fields = ['client_id', 'campaign_id', 'group_id', 'city_criteria_id',\n",
    "           'country_criteria_id', 'external_customer_id', 'metro_criteria_id',\n",
    "           'region_criteria_id']\n",
    "    \n",
    "    df[id_fields] = df[id_fields].astype(object)\n",
    "    \n",
    "    group_by_fields = ['client_id',\n",
    "    'external_customer_id',\n",
    "    'group_id', \n",
    "    'account_descriptive_name', \n",
    "    'ad_network_type',\n",
    "    'campaign_id', \n",
    "    'campaign_name',  \n",
    "    'week_day',\n",
    "    'weekday_num']\n",
    "    \n",
    "    \n",
    "    df_grouped = df.groupby(group_by_fields).agg({'clicks': ['mean', 'sum'], 'impressions': 'sum', 'cost': ['mean', 'sum']}).reset_index()\n",
    "    df_grouped.columns = [\"_\".join(a) for a in df_grouped.columns.to_flat_index()]\n",
    "    df_grouped.columns=df_grouped.columns.str.strip('_')\n",
    "    df_grouped['cost_sum'] = df_grouped['cost_sum']/1000000\n",
    "    df_grouped['cost_sum'] = df_grouped['cost_sum']/1000000\n",
    "    df_grouped['avg_ctr'] = df_grouped['clicks_sum']/df_grouped['impressions_sum']\n",
    "    df_grouped['avg_cpc'] = df_grouped['cost_sum']/df_grouped['clicks_sum']\n",
    "    df_grouped['total_cost'] = df_grouped['cost_sum']\n",
    "    df_grouped['total_clicks'] = df_grouped['clicks_sum']\n",
    "    df_grouped['total_impressions'] = df_grouped['impressions_sum']\n",
    "    df_grouped['avg_clicks'] = df_grouped['clicks_mean']\n",
    "    df_grouped['avg_cost'] = df_grouped['cost_mean']\n",
    "    \n",
    "    df_grouped = df_grouped.drop(['weekday_num','clicks_sum', 'impressions_sum', 'cost_sum', 'cost_mean', 'clicks_mean'], axis=1, errors='ignore')\n",
    "    df_grouped = df_grouped.fillna(0)\n",
    "    df_grouped = df_grouped[df_grouped.avg_cpc > 0]\n",
    "    \n",
    "    df_train = df_grouped.drop(['avg_cpc', 'avg_ctr'], axis=1)\n",
    "    \n",
    "    group_by_fields.remove('weekday_num')\n",
    "    print(df_grouped.columns)\n",
    "    \n",
    "    train_data = df_grouped[group_by_fields + ['avg_cpc']]\n",
    "    \n",
    "    train_labels = df_grouped['avg_ctr']\n",
    "    \n",
    "    cat_features = [i for i in range(len(group_by_fields))]\n",
    "    model = CatBoostRegressor(iterations=1000)\n",
    "    model.fit(train_data,\n",
    "              train_labels,\n",
    "              cat_features,\n",
    "              verbose=True)\n",
    "    \n",
    "    train_preds = model.predict(train_data)\n",
    "    print('RMSE error of catboost oracle: ' + str(np.sqrt(mean_squared_error(train_labels, train_preds))))\n",
    "    print('Median of target variable: ' + str(np.median(train_labels)))\n",
    "    print('Mean of target variable: ' + str(np.mean(train_labels)))\n",
    "    # train the bandit example\n",
    "    bandit = ContextualContinuumArmedBandit(df_train, model, bid_max_value=1.0)\n",
    "    \n",
    "    dill.dump(bandit, open(\"C:\\\\Users\\\\PrasunGhosh\\\\Desktop\\\\ContextualContinuumArmedBanditCloud_JOT_v1.dill\", \"wb\"))\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-5.m71",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-5:m71"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
